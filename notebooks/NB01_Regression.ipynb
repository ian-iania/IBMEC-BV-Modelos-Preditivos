{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Logo BV IBMEC](https://raw.githubusercontent.com/ian-iania/IBMEC-BV-Modelos-Preditivos/main/logo-bv-ibmec-notebooks.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ian-iania/IBMEC-BV-Modelos-Preditivos/blob/main/notebooks/NB01_Regression.ipynb)\n",
        "\n",
        "# NB01 - Regressão e Séries Temporais (FP&A Banco BV)\n",
        "\n",
        "**Objetivo:** aplicar modelos de regressão e séries temporais em dados sintéticos de FP&A do BV, com linguagem simples e foco em negócio.\n",
        "**Neste notebook, vamos comparar baseline e modelos usando split temporal e métricas MAE/RMSE.**\n",
        "**A ideia é entender o processo de ponta a ponta, sem exigir experiência prévia em programação.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Setup do notebook\n",
        "\n",
        "### O que vamos fazer\n",
        "Importar bibliotecas usadas na aula.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Essas bibliotecas permitem carregar dados, calcular métricas e visualizar resultados.\n",
        "\n",
        "### O que você deve ver no output\n",
        "Sem erro de execução.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd  # biblioteca para carregar e manipular tabelas (DataFrames)\n",
        "import numpy as np  # biblioteca para operações numéricas\n",
        "import matplotlib.pyplot as plt  # biblioteca para criar gráficos\n",
        "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet  # modelos lineares\n",
        "from sklearn.tree import DecisionTreeRegressor  # modelo de árvore de decisão\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor  # modelos de ensemble baseados em árvores\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error  # métricas de avaliação MAE e RMSE\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing  # modelo ETS (Holt-Winters)\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX  # modelo ARIMA/ARIMAX\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) PARTE A - Regressão com dataset linear (X -> y)\n",
        "\n",
        "### O que vamos fazer\n",
        "Carregar o dataset linear e construir modelos que explicam `y` a partir de drivers (`X`).\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Esse formato ajuda a responder: \"quanto a originação muda se um driver mudar?\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Carregar dados prontos\n",
        "\n",
        "Os datasets já foram gerados e estão prontos para uso. Aqui vamos carregar direto do GitHub.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "url_linear = 'https://raw.githubusercontent.com/ian-iania/IBMEC-BV-Modelos-Preditivos/main/data/bv_fpa_regressao_linear.csv'  # URL do dataset linear\n",
        "df_lin = pd.read_csv(url_linear)  # leitura do CSV para DataFrame\n",
        "df_lin['ds'] = pd.to_datetime(df_lin['ds'])  # conversão da coluna de data para tipo datetime\n",
        "df_lin.head()  # visualização das primeiras linhas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Dicionário das colunas (muito importante)\n",
        "\n",
        "- `ds`: data de referência mensal (início do mês)\n",
        "- `y`: originação mensal (R$ milhões) -> **variável alvo**\n",
        "- `selic`: taxa SELIC\n",
        "- `desemprego`: taxa de desemprego\n",
        "- `ltv_medio`: Loan-to-Value médio da carteira\n",
        "- `spread`: spread médio (relacionado à SELIC)\n",
        "- `marketing`: esforço/investimento de marketing (índice sintético)\n",
        "- `mix_auto`: participação do mix auto (0 a 1)\n",
        "- `mes`: mês numérico (1 a 12), usado para sazonalidade\n",
        "\n",
        "Se quiser pensar em nomes mais \"de negócio\":\n",
        "- `ds` = `data_referencia`\n",
        "- `y` = `originacao_mensal_m`\n",
        "\n",
        "Neste notebook manteremos `ds` e `y` porque esses nomes são padrão em modelos como Prophet.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('shape:', df_lin.shape)  # exibe quantidade de linhas e colunas\n",
        "print('colunas:', list(df_lin.columns))  # lista todas as colunas da base\n",
        "print('tipos:')  # título visual para facilitar leitura\n",
        "print(df_lin.dtypes)  # mostra o tipo de cada coluna\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Visualização inicial\n",
        "\n",
        "### O que vamos fazer\n",
        "Ver comportamento temporal de `y` e relação simples entre `selic` e `y`.\n",
        "\n",
        "### O que você deve ver no output\n",
        "Um gráfico de linha e um gráfico de dispersão.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 4))  # cria a área do gráfico com tamanho definido\n",
        "plt.plot(df_lin['ds'], df_lin['y'], linewidth=2)  # plota y ao longo do tempo\n",
        "plt.title('PARTE A - Originação (y) ao longo do tempo')  # define o título do gráfico\n",
        "plt.xlabel('Data')  # define o rótulo do eixo X\n",
        "plt.ylabel('y (R$ milhões)')  # define o rótulo do eixo Y\n",
        "plt.grid(alpha=0.3)  # adiciona grade para facilitar leitura\n",
        "plt.show()  # renderiza o gráfico na saída\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))  # cria a área do gráfico de dispersão\n",
        "plt.scatter(df_lin['selic'], df_lin['y'], alpha=0.75)  # plota pontos SELIC x y\n",
        "plt.title('PARTE A - SELIC vs y')  # define o título do gráfico\n",
        "plt.xlabel('SELIC')  # define o rótulo do eixo X\n",
        "plt.ylabel('y (R$ milhões)')  # define o rótulo do eixo Y\n",
        "plt.grid(alpha=0.3)  # adiciona grade para facilitar leitura\n",
        "plt.show()  # renderiza o gráfico na saída\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Conceito de split temporal (sem embaralhar)\n",
        "\n",
        "### O que vamos fazer\n",
        "Separar treino e teste por tempo (80/20):\n",
        "- Treino: período mais antigo\n",
        "- Teste: período mais recente\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "No mundo real, sempre prevemos o futuro com base no passado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = ['selic', 'desemprego', 'ltv_medio', 'spread', 'marketing', 'mix_auto', 'mes']  # lista de variáveis explicativas\n",
        "split_idx = int(len(df_lin) * 0.8)  # calcula ponto de corte de 80% para treino\n",
        "train_lin = df_lin.iloc[:split_idx].copy()  # recorte do treino (parte inicial)\n",
        "test_lin = df_lin.iloc[split_idx:].copy()  # recorte do teste (parte final)\n",
        "X_train_lin = train_lin[features]  # matriz de features no treino\n",
        "X_test_lin = test_lin[features]  # matriz de features no teste\n",
        "y_train_lin = train_lin['y']  # vetor alvo no treino\n",
        "y_test_lin = test_lin['y']  # vetor alvo no teste\n",
        "print('Treino:', X_train_lin.shape, 'Teste:', X_test_lin.shape)  # exibe tamanhos das matrizes\n",
        "print('Período treino:', train_lin['ds'].min().date(), '->', train_lin['ds'].max().date())  # exibe janela temporal de treino\n",
        "print('Período teste :', test_lin['ds'].min().date(), '->', test_lin['ds'].max().date())  # exibe janela temporal de teste\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5 Baseline (referência mínima)\n",
        "\n",
        "### O que vamos fazer\n",
        "Criar baseline naive: repetir no teste o último valor observado no treino.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Um modelo só vale a pena se superar baseline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_value_lin = y_train_lin.iloc[-1]  # captura último valor de y no treino\n",
        "pred_baseline_lin = np.repeat(baseline_value_lin, len(y_test_lin))  # repete o último valor para todos os meses do teste\n",
        "mae_baseline_lin = mean_absolute_error(y_test_lin, pred_baseline_lin)  # calcula MAE do baseline\n",
        "rmse_baseline_lin = np.sqrt(mean_squared_error(y_test_lin, pred_baseline_lin))  # calcula RMSE do baseline\n",
        "print('Baseline MAE :', round(mae_baseline_lin, 3))  # imprime MAE arredondado\n",
        "print('Baseline RMSE:', round(rmse_baseline_lin, 3))  # imprime RMSE arredondado\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.6 Modelos de regressão (execução linear)\n",
        "\n",
        "Vamos treinar um modelo por célula, de forma didática.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_lr = LinearRegression()  # cria modelo de regressão linear\n",
        "model_lr.fit(X_train_lin, y_train_lin)  # treina modelo com dados de treino\n",
        "pred_lr = model_lr.predict(X_test_lin)  # gera previsões para o teste\n",
        "mae_lr = mean_absolute_error(y_test_lin, pred_lr)  # calcula MAE da regressão linear\n",
        "rmse_lr = np.sqrt(mean_squared_error(y_test_lin, pred_lr))  # calcula RMSE da regressão linear\n",
        "print('LinearRegression RMSE:', round(rmse_lr, 3))  # imprime RMSE para consulta rápida\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_ridge = Ridge(alpha=1.0, random_state=42)  # cria modelo Ridge com parâmetro alpha\n",
        "model_ridge.fit(X_train_lin, y_train_lin)  # treina modelo Ridge\n",
        "pred_ridge = model_ridge.predict(X_test_lin)  # gera previsões no teste\n",
        "mae_ridge = mean_absolute_error(y_test_lin, pred_ridge)  # calcula MAE do Ridge\n",
        "rmse_ridge = np.sqrt(mean_squared_error(y_test_lin, pred_ridge))  # calcula RMSE do Ridge\n",
        "print('Ridge RMSE:', round(rmse_ridge, 3))  # imprime RMSE para consulta rápida\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_en = ElasticNet(alpha=0.05, l1_ratio=0.5, random_state=42, max_iter=5000)  # cria modelo ElasticNet\n",
        "model_en.fit(X_train_lin, y_train_lin)  # treina modelo ElasticNet\n",
        "pred_en = model_en.predict(X_test_lin)  # gera previsões no teste\n",
        "mae_en = mean_absolute_error(y_test_lin, pred_en)  # calcula MAE do ElasticNet\n",
        "rmse_en = np.sqrt(mean_squared_error(y_test_lin, pred_en))  # calcula RMSE do ElasticNet\n",
        "print('ElasticNet RMSE:', round(rmse_en, 3))  # imprime RMSE para consulta rápida\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_tree = DecisionTreeRegressor(max_depth=4, random_state=42)  # cria árvore de decisão com profundidade controlada\n",
        "model_tree.fit(X_train_lin, y_train_lin)  # treina árvore de decisão\n",
        "pred_tree = model_tree.predict(X_test_lin)  # gera previsões no teste\n",
        "mae_tree = mean_absolute_error(y_test_lin, pred_tree)  # calcula MAE da árvore\n",
        "rmse_tree = np.sqrt(mean_squared_error(y_test_lin, pred_tree))  # calcula RMSE da árvore\n",
        "print('DecisionTree RMSE:', round(rmse_tree, 3))  # imprime RMSE para consulta rápida\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_rf = RandomForestRegressor(n_estimators=300, max_depth=6, random_state=42)  # cria Random Forest com 300 árvores\n",
        "model_rf.fit(X_train_lin, y_train_lin)  # treina Random Forest\n",
        "pred_rf = model_rf.predict(X_test_lin)  # gera previsões no teste\n",
        "mae_rf = mean_absolute_error(y_test_lin, pred_rf)  # calcula MAE do Random Forest\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test_lin, pred_rf))  # calcula RMSE do Random Forest\n",
        "print('RandomForest RMSE:', round(rmse_rf, 3))  # imprime RMSE para consulta rápida\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_gbm = GradientBoostingRegressor(random_state=42)  # cria Gradient Boosting com semente fixa\n",
        "model_gbm.fit(X_train_lin, y_train_lin)  # treina Gradient Boosting\n",
        "pred_gbm = model_gbm.predict(X_test_lin)  # gera previsões no teste\n",
        "mae_gbm = mean_absolute_error(y_test_lin, pred_gbm)  # calcula MAE do Gradient Boosting\n",
        "rmse_gbm = np.sqrt(mean_squared_error(y_test_lin, pred_gbm))  # calcula RMSE do Gradient Boosting\n",
        "print('GradientBoosting RMSE:', round(rmse_gbm, 3))  # imprime RMSE para consulta rápida\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_a = pd.DataFrame([  # cria tabela de resultados da PARTE A\n",
        "    {'modelo': 'Baseline_Naive', 'mae': mae_baseline_lin, 'rmse': rmse_baseline_lin},  # linha do baseline\n",
        "    {'modelo': 'LinearRegression', 'mae': mae_lr, 'rmse': rmse_lr},  # linha do LinearRegression\n",
        "    {'modelo': 'Ridge', 'mae': mae_ridge, 'rmse': rmse_ridge},  # linha do Ridge\n",
        "    {'modelo': 'ElasticNet', 'mae': mae_en, 'rmse': rmse_en},  # linha do ElasticNet\n",
        "    {'modelo': 'DecisionTree', 'mae': mae_tree, 'rmse': rmse_tree},  # linha da árvore\n",
        "    {'modelo': 'RandomForest', 'mae': mae_rf, 'rmse': rmse_rf},  # linha do RandomForest\n",
        "    {'modelo': 'GradientBoosting', 'mae': mae_gbm, 'rmse': rmse_gbm},  # linha do GradientBoosting\n",
        "]).sort_values('rmse').reset_index(drop=True)  # ordena por melhor RMSE\n",
        "results_a  # exibe tabela final da PARTE A\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_linear_name = results_a[results_a['modelo'].isin(['LinearRegression', 'Ridge', 'ElasticNet'])].iloc[0]['modelo']  # identifica melhor linear\n",
        "best_nonlinear_name = results_a[results_a['modelo'].isin(['DecisionTree', 'RandomForest', 'GradientBoosting'])].iloc[0]['modelo']  # identifica melhor não-linear\n",
        "pred_map_a = {  # mapeia nome do modelo para seu vetor de previsão\n",
        "    'LinearRegression': pred_lr,  # previsões do LinearRegression\n",
        "    'Ridge': pred_ridge,  # previsões do Ridge\n",
        "    'ElasticNet': pred_en,  # previsões do ElasticNet\n",
        "    'DecisionTree': pred_tree,  # previsões da árvore\n",
        "    'RandomForest': pred_rf,  # previsões do RandomForest\n",
        "    'GradientBoosting': pred_gbm,  # previsões do GradientBoosting\n",
        "}  # fim do dicionário de previsões\n",
        "plt.figure(figsize=(11, 4))  # cria área do gráfico comparativo\n",
        "plt.plot(test_lin['ds'], y_test_lin.values, label='Real', color='black', linewidth=2)  # plota série real\n",
        "plt.plot(test_lin['ds'], pred_baseline_lin, label='Baseline_Naive', linewidth=1.8)  # plota baseline\n",
        "plt.plot(test_lin['ds'], pred_map_a[best_linear_name], label=f'Melhor linear: {best_linear_name}', linewidth=1.8)  # plota melhor linear\n",
        "plt.plot(test_lin['ds'], pred_map_a[best_nonlinear_name], label=f'Melhor não-linear: {best_nonlinear_name}', linewidth=1.8)  # plota melhor não-linear\n",
        "plt.title('PARTE A - Real vs Previsto (teste)')  # define título do gráfico\n",
        "plt.xlabel('Data')  # define rótulo do eixo X\n",
        "plt.ylabel('y (R$ milhões)')  # define rótulo do eixo Y\n",
        "plt.legend()  # exibe legenda\n",
        "plt.grid(alpha=0.3)  # adiciona grade\n",
        "plt.show()  # renderiza gráfico\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.7 Feature importance\n",
        "\n",
        "### O que vamos fazer\n",
        "Mostrar importância das variáveis em modelos de árvore.\n",
        "\n",
        "### Observação importante\n",
        "Importância ajuda na leitura, mas **não significa causalidade**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_imp = pd.Series(model_rf.feature_importances_, index=features).sort_values(ascending=True)  # calcula importâncias do RandomForest\n",
        "gbm_imp = pd.Series(model_gbm.feature_importances_, index=features).sort_values(ascending=True)  # calcula importâncias do GradientBoosting\n",
        "plt.figure(figsize=(12, 4))  # cria figura com dois gráficos lado a lado\n",
        "plt.subplot(1, 2, 1)  # ativa painel 1\n",
        "plt.barh(rf_imp.index, rf_imp.values)  # plota barras horizontais do RandomForest\n",
        "plt.title('Importância - RandomForest')  # define título do painel 1\n",
        "plt.grid(axis='x', alpha=0.3)  # adiciona grade horizontal no painel 1\n",
        "plt.subplot(1, 2, 2)  # ativa painel 2\n",
        "plt.barh(gbm_imp.index, gbm_imp.values)  # plota barras horizontais do GradientBoosting\n",
        "plt.title('Importância - GradientBoosting')  # define título do painel 2\n",
        "plt.grid(axis='x', alpha=0.3)  # adiciona grade horizontal no painel 2\n",
        "plt.tight_layout()  # ajusta espaçamento entre painéis\n",
        "plt.show()  # renderiza os dois painéis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) PARTE B - Mesmo pipeline no dataset não-linear\n",
        "\n",
        "### O que vamos fazer\n",
        "Repetir o mesmo fluxo no dataset com não-linearidades.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Assim vemos quando modelos não-lineares capturam melhor os padrões.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "url_nlin = 'https://raw.githubusercontent.com/ian-iania/IBMEC-BV-Modelos-Preditivos/main/data/bv_fpa_regressao_nonlinear.csv'  # URL do dataset não-linear\n",
        "df_nlin = pd.read_csv(url_nlin)  # leitura do CSV não-linear\n",
        "df_nlin['ds'] = pd.to_datetime(df_nlin['ds'])  # conversão da data para datetime\n",
        "df_nlin.head()  # visualização inicial do dataset não-linear\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_idx_b = int(len(df_nlin) * 0.8)  # calcula ponto de corte de 80% para treino\n",
        "train_nlin = df_nlin.iloc[:split_idx_b].copy()  # separa período de treino\n",
        "train_nlin = train_nlin.sort_values('ds')  # garante ordenação temporal no treino\n",
        "test_nlin = df_nlin.iloc[split_idx_b:].copy()  # separa período de teste\n",
        "test_nlin = test_nlin.sort_values('ds')  # garante ordenação temporal no teste\n",
        "X_train_nlin = train_nlin[features]  # extrai features de treino\n",
        "X_test_nlin = test_nlin[features]  # extrai features de teste\n",
        "y_train_nlin = train_nlin['y']  # extrai alvo de treino\n",
        "y_test_nlin = test_nlin['y']  # extrai alvo de teste\n",
        "baseline_value_nlin = y_train_nlin.iloc[-1]  # captura último valor de treino para baseline\n",
        "pred_baseline_nlin = np.repeat(baseline_value_nlin, len(y_test_nlin))  # monta previsão constante do baseline\n",
        "mae_baseline_nlin = mean_absolute_error(y_test_nlin, pred_baseline_nlin)  # calcula MAE do baseline não-linear\n",
        "rmse_baseline_nlin = np.sqrt(mean_squared_error(y_test_nlin, pred_baseline_nlin))  # calcula RMSE do baseline não-linear\n",
        "print('Baseline RMSE (não-linear):', round(rmse_baseline_nlin, 3))  # imprime RMSE do baseline da PARTE B\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_lr_b = LinearRegression()  # cria LinearRegression da PARTE B\n",
        "model_lr_b.fit(X_train_nlin, y_train_nlin)  # treina LinearRegression na base não-linear\n",
        "pred_lr_b = model_lr_b.predict(X_test_nlin)  # gera previsões LinearRegression na PARTE B\n",
        "model_ridge_b = Ridge(alpha=1.0, random_state=42)  # cria Ridge da PARTE B\n",
        "model_ridge_b.fit(X_train_nlin, y_train_nlin)  # treina Ridge na base não-linear\n",
        "pred_ridge_b = model_ridge_b.predict(X_test_nlin)  # gera previsões Ridge na PARTE B\n",
        "model_en_b = ElasticNet(alpha=0.05, l1_ratio=0.5, random_state=42, max_iter=5000)  # cria ElasticNet da PARTE B\n",
        "model_en_b.fit(X_train_nlin, y_train_nlin)  # treina ElasticNet na base não-linear\n",
        "pred_en_b = model_en_b.predict(X_test_nlin)  # gera previsões ElasticNet na PARTE B\n",
        "model_tree_b = DecisionTreeRegressor(max_depth=4, random_state=42)  # cria árvore da PARTE B\n",
        "model_tree_b.fit(X_train_nlin, y_train_nlin)  # treina árvore na base não-linear\n",
        "pred_tree_b = model_tree_b.predict(X_test_nlin)  # gera previsões da árvore na PARTE B\n",
        "model_rf_b = RandomForestRegressor(n_estimators=300, max_depth=6, random_state=42)  # cria RandomForest da PARTE B\n",
        "model_rf_b.fit(X_train_nlin, y_train_nlin)  # treina RandomForest na base não-linear\n",
        "pred_rf_b = model_rf_b.predict(X_test_nlin)  # gera previsões RandomForest na PARTE B\n",
        "model_gbm_b = GradientBoostingRegressor(random_state=42)  # cria GradientBoosting da PARTE B\n",
        "model_gbm_b.fit(X_train_nlin, y_train_nlin)  # treina GradientBoosting na base não-linear\n",
        "pred_gbm_b = model_gbm_b.predict(X_test_nlin)  # gera previsões GradientBoosting na PARTE B\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_b = pd.DataFrame([  # cria tabela de resultados da PARTE B\n",
        "    {'modelo': 'Baseline_Naive', 'mae': mae_baseline_nlin, 'rmse': rmse_baseline_nlin},  # linha baseline\n",
        "    {'modelo': 'LinearRegression', 'mae': mean_absolute_error(y_test_nlin, pred_lr_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_lr_b))},  # linha linear\n",
        "    {'modelo': 'Ridge', 'mae': mean_absolute_error(y_test_nlin, pred_ridge_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_ridge_b))},  # linha ridge\n",
        "    {'modelo': 'ElasticNet', 'mae': mean_absolute_error(y_test_nlin, pred_en_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_en_b))},  # linha elasticnet\n",
        "    {'modelo': 'DecisionTree', 'mae': mean_absolute_error(y_test_nlin, pred_tree_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_tree_b))},  # linha árvore\n",
        "    {'modelo': 'RandomForest', 'mae': mean_absolute_error(y_test_nlin, pred_rf_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_rf_b))},  # linha random forest\n",
        "    {'modelo': 'GradientBoosting', 'mae': mean_absolute_error(y_test_nlin, pred_gbm_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_gbm_b))},  # linha gradient boosting\n",
        "]).sort_values('rmse').reset_index(drop=True)  # ordena por melhor RMSE\n",
        "results_b  # exibe ranking final da PARTE B\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_linear_b = results_b[results_b['modelo'].isin(['LinearRegression', 'Ridge', 'ElasticNet'])].iloc[0]['modelo']  # identifica melhor modelo linear da PARTE B\n",
        "best_nonlinear_b = results_b[results_b['modelo'].isin(['DecisionTree', 'RandomForest', 'GradientBoosting'])].iloc[0]['modelo']  # identifica melhor modelo não-linear da PARTE B\n",
        "pred_map_b = {  # mapeia nome para vetor de previsão na PARTE B\n",
        "    'LinearRegression': pred_lr_b,  # previsões linear\n",
        "    'Ridge': pred_ridge_b,  # previsões ridge\n",
        "    'ElasticNet': pred_en_b,  # previsões elasticnet\n",
        "    'DecisionTree': pred_tree_b,  # previsões árvore\n",
        "    'RandomForest': pred_rf_b,  # previsões random forest\n",
        "    'GradientBoosting': pred_gbm_b,  # previsões gradient boosting\n",
        "}  # fim do dicionário de previsões da PARTE B\n",
        "plt.figure(figsize=(11, 4))  # cria área do gráfico comparativo da PARTE B\n",
        "plt.plot(test_nlin['ds'], y_test_nlin.values, label='Real', color='black', linewidth=2)  # plota série real da PARTE B\n",
        "plt.plot(test_nlin['ds'], pred_map_b[best_linear_b], label=f'Melhor linear: {best_linear_b}', linewidth=1.8)  # plota melhor linear da PARTE B\n",
        "plt.plot(test_nlin['ds'], pred_map_b[best_nonlinear_b], label=f'Melhor não-linear: {best_nonlinear_b}', linewidth=1.8)  # plota melhor não-linear da PARTE B\n",
        "plt.title('PARTE B - Melhor linear vs melhor não-linear (teste)')  # define título do gráfico da PARTE B\n",
        "plt.xlabel('Data')  # define rótulo do eixo X na PARTE B\n",
        "plt.ylabel('y (R$ milhões)')  # define rótulo do eixo Y na PARTE B\n",
        "plt.legend()  # exibe legenda da PARTE B\n",
        "plt.grid(alpha=0.3)  # adiciona grade da PARTE B\n",
        "plt.show()  # renderiza gráfico da PARTE B\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) PARTE C - Séries temporais (t -> y)\n",
        "\n",
        "### O que vamos fazer\n",
        "Comparar baseline, ETS, ARIMA, ARIMAX e Prophet (opcional).\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Em vários contextos, o próprio histórico de `y` já é forte para previsão.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "url_ts = 'https://raw.githubusercontent.com/ian-iania/IBMEC-BV-Modelos-Preditivos/main/data/bv_fpa_timeseries.csv'  # URL do dataset de séries temporais\n",
        "df_ts = pd.read_csv(url_ts)  # leitura do CSV de séries temporais\n",
        "df_ts['ds'] = pd.to_datetime(df_ts['ds'])  # conversão da data para datetime\n",
        "df_ts.head()  # visualização inicial do dataset temporal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 4))  # cria figura para gráfico temporal\n",
        "plt.plot(df_ts['ds'], df_ts['y'], linewidth=2)  # plota y ao longo do tempo\n",
        "plt.title('PARTE C - Série temporal y')  # define título do gráfico temporal\n",
        "plt.xlabel('Data')  # define eixo X no gráfico temporal\n",
        "plt.ylabel('y (R$ milhões)')  # define eixo Y no gráfico temporal\n",
        "plt.grid(alpha=0.3)  # adiciona grade no gráfico temporal\n",
        "plt.show()  # renderiza gráfico temporal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "holdout = 12  # define os últimos 12 meses como teste\n",
        "train_ts = df_ts.iloc[:-holdout].copy()  # separa parte inicial da série para treino\n",
        "test_ts = df_ts.iloc[-holdout:].copy()  # separa parte final da série para teste\n",
        "y_train_ts = train_ts['y'].values  # vetor alvo de treino em formato numpy\n",
        "y_test_ts = test_ts['y'].values  # vetor alvo de teste em formato numpy\n",
        "print('Treino:', train_ts.shape, 'Teste:', test_ts.shape)  # imprime tamanhos de treino e teste\n",
        "print('Período treino:', train_ts['ds'].min().date(), '->', train_ts['ds'].max().date())  # imprime janela temporal de treino\n",
        "print('Período teste :', test_ts['ds'].min().date(), '->', test_ts['ds'].max().date())  # imprime janela temporal de teste\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_naive_ts = np.repeat(y_train_ts[-1], len(y_test_ts))  # cria baseline naive repetindo último valor do treino\n",
        "mae_naive_ts = mean_absolute_error(y_test_ts, pred_naive_ts)  # calcula MAE do baseline temporal\n",
        "rmse_naive_ts = np.sqrt(mean_squared_error(y_test_ts, pred_naive_ts))  # calcula RMSE do baseline temporal\n",
        "print('Baseline MAE :', round(mae_naive_ts, 3))  # imprime MAE do baseline temporal\n",
        "print('Baseline RMSE:', round(rmse_naive_ts, 3))  # imprime RMSE do baseline temporal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ets = ExponentialSmoothing(train_ts['y'], trend='add', seasonal='add', seasonal_periods=12).fit(optimized=True)  # ajusta modelo ETS\n",
        "pred_ets = ets.forecast(len(test_ts)).values  # gera previsão ETS para o período de teste\n",
        "mae_ets = mean_absolute_error(y_test_ts, pred_ets)  # calcula MAE do ETS\n",
        "rmse_ets = np.sqrt(mean_squared_error(y_test_ts, pred_ets))  # calcula RMSE do ETS\n",
        "print('ETS MAE :', round(mae_ets, 3))  # imprime MAE do ETS\n",
        "print('ETS RMSE:', round(rmse_ets, 3))  # imprime RMSE do ETS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arima = SARIMAX(train_ts['y'], order=(1, 1, 1), enforce_stationarity=False, enforce_invertibility=False).fit(disp=False)  # ajusta modelo ARIMA\n",
        "pred_arima = arima.forecast(steps=len(test_ts)).values  # gera previsão ARIMA para o teste\n",
        "mae_arima = mean_absolute_error(y_test_ts, pred_arima)  # calcula MAE do ARIMA\n",
        "rmse_arima = np.sqrt(mean_squared_error(y_test_ts, pred_arima))  # calcula RMSE do ARIMA\n",
        "print('ARIMA MAE :', round(mae_arima, 3))  # imprime MAE do ARIMA\n",
        "print('ARIMA RMSE:', round(rmse_arima, 3))  # imprime RMSE do ARIMA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arimax = SARIMAX(train_ts['y'], exog=train_ts[['selic']], order=(1, 1, 1), enforce_stationarity=False, enforce_invertibility=False).fit(disp=False)  # ajusta ARIMAX com selic\n",
        "pred_arimax = arimax.forecast(steps=len(test_ts), exog=test_ts[['selic']]).values  # gera previsão ARIMAX usando selic no teste\n",
        "mae_arimax = mean_absolute_error(y_test_ts, pred_arimax)  # calcula MAE do ARIMAX\n",
        "rmse_arimax = np.sqrt(mean_squared_error(y_test_ts, pred_arimax))  # calcula RMSE do ARIMAX\n",
        "print('ARIMAX MAE :', round(mae_arimax, 3))  # imprime MAE do ARIMAX\n",
        "print('ARIMAX RMSE:', round(rmse_arimax, 3))  # imprime RMSE do ARIMAX\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Prophet (opcional)\n",
        "\n",
        "Prophet pode demorar para instalar em algumas sessões do Colab.\n",
        "Se não funcionar, continue a aula normalmente com ETS/ARIMA/ARIMAX.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess  # módulo para executar comando de instalação\n",
        "import sys  # módulo para descobrir o executável Python atual\n",
        "prophet_ok = False  # flag para indicar disponibilidade do Prophet\n",
        "try:  # tenta importar Prophet direto\n",
        "    from prophet import Prophet  # importa classe Prophet se já estiver instalada\n",
        "    prophet_ok = True  # marca que Prophet está disponível\n",
        "    print('Prophet já disponível.')  # informa disponibilidade imediata\n",
        "except Exception:  # captura erro de importação\n",
        "    print('Tentando instalar Prophet...')  # avisa tentativa de instalação\n",
        "    try:  # tenta instalar via pip\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'prophet', '-q'])  # executa instalação silenciosa\n",
        "        from prophet import Prophet  # importa novamente após instalar\n",
        "        prophet_ok = True  # marca sucesso da instalação\n",
        "        print('Prophet instalado com sucesso.')  # confirma instalação\n",
        "    except Exception as e:  # captura erro na instalação\n",
        "        print('Prophet indisponível nesta sessão.')  # avisa indisponibilidade\n",
        "        print('Erro:', e)  # mostra detalhe do erro\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_prophet = None  # inicializa previsão do Prophet como vazia\n",
        "mae_prophet = None  # inicializa MAE do Prophet como vazio\n",
        "rmse_prophet = None  # inicializa RMSE do Prophet como vazio\n",
        "if prophet_ok:  # executa bloco apenas se Prophet estiver disponível\n",
        "    train_prophet = train_ts[['ds', 'y', 'selic', 'evento']].copy()  # cria base de treino no formato Prophet\n",
        "    test_prophet = test_ts[['ds', 'selic', 'evento']].copy()  # cria base de teste no formato Prophet\n",
        "    m = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)  # cria modelo Prophet com sazonalidade anual\n",
        "    m.add_regressor('selic')  # adiciona selic como regressora adicional\n",
        "    m.add_regressor('evento')  # adiciona evento como regressora adicional\n",
        "    m.fit(train_prophet)  # treina Prophet com dados de treino\n",
        "    fcst = m.predict(test_prophet)  # gera previsão para período de teste\n",
        "    pred_prophet = fcst['yhat'].values  # extrai vetor previsto do Prophet\n",
        "    mae_prophet = mean_absolute_error(y_test_ts, pred_prophet)  # calcula MAE do Prophet\n",
        "    rmse_prophet = np.sqrt(mean_squared_error(y_test_ts, pred_prophet))  # calcula RMSE do Prophet\n",
        "    print('Prophet MAE :', round(mae_prophet, 3))  # imprime MAE do Prophet\n",
        "    print('Prophet RMSE:', round(rmse_prophet, 3))  # imprime RMSE do Prophet\n",
        "else:  # executa bloco alternativo se Prophet não estiver disponível\n",
        "    print('Prophet não executado.')  # informa que etapa foi pulada\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_c = pd.DataFrame([  # cria tabela base de resultados da PARTE C\n",
        "    {'modelo': 'Baseline_Naive', 'mae': mae_naive_ts, 'rmse': rmse_naive_ts},  # linha baseline\n",
        "    {'modelo': 'ETS_HoltWinters', 'mae': mae_ets, 'rmse': rmse_ets},  # linha ETS\n",
        "    {'modelo': 'ARIMA', 'mae': mae_arima, 'rmse': rmse_arima},  # linha ARIMA\n",
        "    {'modelo': 'ARIMAX_selic', 'mae': mae_arimax, 'rmse': rmse_arimax},  # linha ARIMAX\n",
        "])  # fecha criação inicial do DataFrame\n",
        "if pred_prophet is not None:  # verifica se Prophet foi executado\n",
        "    results_c = pd.concat([results_c, pd.DataFrame([{'modelo': 'Prophet', 'mae': mae_prophet, 'rmse': rmse_prophet}])], ignore_index=True)  # adiciona linha do Prophet\n",
        "results_c = results_c.sort_values('rmse').reset_index(drop=True)  # ordena tabela final por RMSE\n",
        "results_c  # exibe ranking final da PARTE C\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(11, 4))  # cria figura do gráfico final da PARTE C\n",
        "plt.plot(test_ts['ds'], y_test_ts, label='Real', color='black', linewidth=2)  # plota série real do teste\n",
        "plt.plot(test_ts['ds'], pred_naive_ts, label='Baseline_Naive', linewidth=1.8)  # plota baseline naive\n",
        "plt.plot(test_ts['ds'], pred_ets, label='ETS_HoltWinters', linewidth=1.8)  # plota previsão ETS\n",
        "plt.plot(test_ts['ds'], pred_arimax, label='ARIMAX_selic', linewidth=1.8)  # plota previsão ARIMAX\n",
        "if pred_prophet is not None:  # verifica se há previsão do Prophet\n",
        "    plt.plot(test_ts['ds'], pred_prophet, label='Prophet', linewidth=1.8)  # plota previsão Prophet quando disponível\n",
        "plt.title('PARTE C - Real vs Previsões (teste)')  # define título do gráfico final\n",
        "plt.xlabel('Data')  # define rótulo do eixo X no gráfico final\n",
        "plt.ylabel('y (R$ milhões)')  # define rótulo do eixo Y no gráfico final\n",
        "plt.legend()  # exibe legenda do gráfico final\n",
        "plt.grid(alpha=0.3)  # adiciona grade do gráfico final\n",
        "plt.show()  # renderiza gráfico final da PARTE C\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Conclusão didática\n",
        "\n",
        "- **X -> y (regressão):** útil quando temos drivers para explicar comportamento da originação.\n",
        "- **t -> y (série temporal):** útil quando o histórico de `y` já carrega padrão forte.\n",
        "- **Regra de ouro:** comparar com baseline e validar no tempo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Checklist FP&A\n",
        "\n",
        "- Baseline: sempre comparar modelo novo com referência simples.\n",
        "- Split temporal: nunca misturar passado e futuro na validação.\n",
        "- Métricas: usar MAE e RMSE no teste para decidir modelo.\n",
        "- Governança: documentar dados, período e versão do modelo.\n",
        "- Monitoramento: revisar performance regularmente e recalibrar quando necessário.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}