{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Logo BV IBMEC](https://raw.githubusercontent.com/ian-iania/IBMEC-BV-Modelos-Preditivos/main/logo-bv-ibmec-notebooks.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ian-iania/IBMEC-BV-Modelos-Preditivos/blob/main/notebooks/NB01_Regression.ipynb)\n",
        "\n",
        "# NB01 - Regressão e Séries Temporais (FP&A Banco BV)\n",
        "\n",
        "**Objetivo:** aplicar regressão e séries temporais em dados sintéticos de FP&A do BV, de forma simples e prática.\n",
        "**Neste notebook, vamos comparar baseline e modelos com split temporal, usando MAE e RMSE.**\n",
        "**Foco total em leitura de negócio, sem complexidade de programação.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Setup simples\n",
        "\n",
        "### O que vamos fazer\n",
        "Importar bibliotecas e definir apenas variáveis básicas.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Menos código técnico, mais foco na análise.\n",
        "\n",
        "### O que você deve ver no output\n",
        "Sem erro de import.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 1 - imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) PARTE A - Regressão com dataset linear (X -> y)\n",
        "\n",
        "### O que vamos fazer\n",
        "Carregar dataset linear e comparar baseline + modelos.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Ajuda a prever originação a partir de drivers de negócio.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 2 - carregar dataset linear (já pronto para uso)\n",
        "url_linear = 'https://raw.githubusercontent.com/ian-iania/IBMEC-BV-Modelos-Preditivos/main/data/bv_fpa_regressao_linear.csv'\n",
        "\n",
        "df_lin = pd.read_csv(url_linear)\n",
        "df_lin['ds'] = pd.to_datetime(df_lin['ds'])\n",
        "\n",
        "df_lin.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 3 - inspeção rápida\n",
        "print('shape:', df_lin.shape)\n",
        "print('colunas:', list(df_lin.columns))\n",
        "print('\n",
        "dtypes:')\n",
        "print(df_lin.dtypes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Visualização inicial\n",
        "\n",
        "### O que vamos fazer\n",
        "Olhar `y` no tempo e relação `selic` vs `y`.\n",
        "\n",
        "### O que você deve ver no output\n",
        "Um gráfico de linha e um gráfico de dispersão.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 4 - linha de y no tempo\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(df_lin['ds'], df_lin['y'], linewidth=2)\n",
        "plt.title('PARTE A - y ao longo do tempo')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('y (R$ milhões)')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 5 - scatter selic vs y\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.scatter(df_lin['selic'], df_lin['y'], alpha=0.75)\n",
        "plt.title('PARTE A - SELIC vs y')\n",
        "plt.xlabel('SELIC')\n",
        "plt.ylabel('y (R$ milhões)')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Split temporal e baseline\n",
        "\n",
        "### O que vamos fazer\n",
        "Separar treino/teste no tempo (80/20), sem embaralhar.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Treinar no passado e testar no futuro.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 6 - preparar X/y e split temporal\n",
        "features = ['selic', 'desemprego', 'ltv_medio', 'spread', 'marketing', 'mix_auto', 'mes']\n",
        "\n",
        "split_idx = int(len(df_lin) * 0.8)\n",
        "train_lin = df_lin.iloc[:split_idx].copy()\n",
        "test_lin = df_lin.iloc[split_idx:].copy()\n",
        "\n",
        "X_train_lin = train_lin[features]\n",
        "X_test_lin = test_lin[features]\n",
        "y_train_lin = train_lin['y']\n",
        "y_test_lin = test_lin['y']\n",
        "\n",
        "print('Treino:', X_train_lin.shape, 'Teste:', X_test_lin.shape)\n",
        "print('Período treino:', train_lin['ds'].min().date(), '->', train_lin['ds'].max().date())\n",
        "print('Período teste :', test_lin['ds'].min().date(), '->', test_lin['ds'].max().date())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 7 - baseline naive (último valor do treino)\n",
        "baseline_value_lin = y_train_lin.iloc[-1]\n",
        "pred_baseline_lin = np.repeat(baseline_value_lin, len(y_test_lin))\n",
        "\n",
        "mae_baseline_lin = mean_absolute_error(y_test_lin, pred_baseline_lin)\n",
        "rmse_baseline_lin = np.sqrt(mean_squared_error(y_test_lin, pred_baseline_lin))\n",
        "\n",
        "print('Baseline MAE :', round(mae_baseline_lin, 3))\n",
        "print('Baseline RMSE:', round(rmse_baseline_lin, 3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Modelos de regressão (simples e direto)\n",
        "\n",
        "### O que vamos fazer\n",
        "Treinar 6 modelos e comparar no mesmo teste.\n",
        "\n",
        "### O que você deve ver no output\n",
        "Tabela ordenada por RMSE.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 8 - Linear Regression\n",
        "model_lr = LinearRegression()\n",
        "model_lr.fit(X_train_lin, y_train_lin)\n",
        "pred_lr = model_lr.predict(X_test_lin)\n",
        "\n",
        "mae_lr = mean_absolute_error(y_test_lin, pred_lr)\n",
        "rmse_lr = np.sqrt(mean_squared_error(y_test_lin, pred_lr))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 9 - Ridge\n",
        "model_ridge = Ridge(alpha=1.0, random_state=42)\n",
        "model_ridge.fit(X_train_lin, y_train_lin)\n",
        "pred_ridge = model_ridge.predict(X_test_lin)\n",
        "\n",
        "mae_ridge = mean_absolute_error(y_test_lin, pred_ridge)\n",
        "rmse_ridge = np.sqrt(mean_squared_error(y_test_lin, pred_ridge))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 10 - ElasticNet\n",
        "model_en = ElasticNet(alpha=0.05, l1_ratio=0.5, random_state=42, max_iter=5000)\n",
        "model_en.fit(X_train_lin, y_train_lin)\n",
        "pred_en = model_en.predict(X_test_lin)\n",
        "\n",
        "mae_en = mean_absolute_error(y_test_lin, pred_en)\n",
        "rmse_en = np.sqrt(mean_squared_error(y_test_lin, pred_en))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 11 - DecisionTree\n",
        "model_tree = DecisionTreeRegressor(max_depth=4, random_state=42)\n",
        "model_tree.fit(X_train_lin, y_train_lin)\n",
        "pred_tree = model_tree.predict(X_test_lin)\n",
        "\n",
        "mae_tree = mean_absolute_error(y_test_lin, pred_tree)\n",
        "rmse_tree = np.sqrt(mean_squared_error(y_test_lin, pred_tree))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 12 - RandomForest\n",
        "model_rf = RandomForestRegressor(n_estimators=300, max_depth=6, random_state=42)\n",
        "model_rf.fit(X_train_lin, y_train_lin)\n",
        "pred_rf = model_rf.predict(X_test_lin)\n",
        "\n",
        "mae_rf = mean_absolute_error(y_test_lin, pred_rf)\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test_lin, pred_rf))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 13 - GradientBoosting\n",
        "model_gbm = GradientBoostingRegressor(random_state=42)\n",
        "model_gbm.fit(X_train_lin, y_train_lin)\n",
        "pred_gbm = model_gbm.predict(X_test_lin)\n",
        "\n",
        "mae_gbm = mean_absolute_error(y_test_lin, pred_gbm)\n",
        "rmse_gbm = np.sqrt(mean_squared_error(y_test_lin, pred_gbm))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 14 - tabela comparativa (PARTE A)\n",
        "results_a = pd.DataFrame([\n",
        "    {'modelo': 'Baseline_Naive', 'mae': mae_baseline_lin, 'rmse': rmse_baseline_lin},\n",
        "    {'modelo': 'LinearRegression', 'mae': mae_lr, 'rmse': rmse_lr},\n",
        "    {'modelo': 'Ridge', 'mae': mae_ridge, 'rmse': rmse_ridge},\n",
        "    {'modelo': 'ElasticNet', 'mae': mae_en, 'rmse': rmse_en},\n",
        "    {'modelo': 'DecisionTree', 'mae': mae_tree, 'rmse': rmse_tree},\n",
        "    {'modelo': 'RandomForest', 'mae': mae_rf, 'rmse': rmse_rf},\n",
        "    {'modelo': 'GradientBoosting', 'mae': mae_gbm, 'rmse': rmse_gbm},\n",
        "]).sort_values('rmse').reset_index(drop=True)\n",
        "\n",
        "results_a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 15 - real vs previsto (baseline, melhor linear, melhor não-linear)\n",
        "best_linear_name = results_a[results_a['modelo'].isin(['LinearRegression', 'Ridge', 'ElasticNet'])].iloc[0]['modelo']\n",
        "best_nonlinear_name = results_a[results_a['modelo'].isin(['DecisionTree', 'RandomForest', 'GradientBoosting'])].iloc[0]['modelo']\n",
        "\n",
        "pred_map_a = {\n",
        "    'LinearRegression': pred_lr,\n",
        "    'Ridge': pred_ridge,\n",
        "    'ElasticNet': pred_en,\n",
        "    'DecisionTree': pred_tree,\n",
        "    'RandomForest': pred_rf,\n",
        "    'GradientBoosting': pred_gbm\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(11, 4))\n",
        "plt.plot(test_lin['ds'], y_test_lin.values, label='Real', color='black', linewidth=2)\n",
        "plt.plot(test_lin['ds'], pred_baseline_lin, label='Baseline_Naive', linewidth=1.8)\n",
        "plt.plot(test_lin['ds'], pred_map_a[best_linear_name], label=f'Melhor linear: {best_linear_name}', linewidth=1.8)\n",
        "plt.plot(test_lin['ds'], pred_map_a[best_nonlinear_name], label=f'Melhor não-linear: {best_nonlinear_name}', linewidth=1.8)\n",
        "plt.title('PARTE A - Real vs Previsto (teste)')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('y (R$ milhões)')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 16 - feature importance (RandomForest e GradientBoosting)\n",
        "rf_imp = pd.Series(model_rf.feature_importances_, index=features).sort_values(ascending=True)\n",
        "gbm_imp = pd.Series(model_gbm.feature_importances_, index=features).sort_values(ascending=True)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.barh(rf_imp.index, rf_imp.values)\n",
        "plt.title('Importância - RandomForest')\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.barh(gbm_imp.index, gbm_imp.values)\n",
        "plt.title('Importância - GradientBoosting')\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Importante:** importância de variável ajuda a priorizar discussão, mas **não prova causalidade**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) PARTE B - Mesmo fluxo no dataset não-linear\n",
        "\n",
        "### O que vamos fazer\n",
        "Repetir o mesmo processo no dataset não-linear.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Quando há limiar/interação, modelos não-lineares costumam performar melhor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 17 - carregar dataset não-linear\n",
        "url_nlin = 'https://raw.githubusercontent.com/ian-iania/IBMEC-BV-Modelos-Preditivos/main/data/bv_fpa_regressao_nonlinear.csv'\n",
        "\n",
        "df_nlin = pd.read_csv(url_nlin)\n",
        "df_nlin['ds'] = pd.to_datetime(df_nlin['ds'])\n",
        "\n",
        "df_nlin.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 18 - split temporal e baseline (PARTE B)\n",
        "split_idx_b = int(len(df_nlin) * 0.8)\n",
        "train_nlin = df_nlin.iloc[:split_idx_b].copy()\n",
        "test_nlin = df_nlin.iloc[split_idx_b:].copy()\n",
        "\n",
        "X_train_nlin = train_nlin[features]\n",
        "X_test_nlin = test_nlin[features]\n",
        "y_train_nlin = train_nlin['y']\n",
        "y_test_nlin = test_nlin['y']\n",
        "\n",
        "baseline_value_nlin = y_train_nlin.iloc[-1]\n",
        "pred_baseline_nlin = np.repeat(baseline_value_nlin, len(y_test_nlin))\n",
        "\n",
        "mae_baseline_nlin = mean_absolute_error(y_test_nlin, pred_baseline_nlin)\n",
        "rmse_baseline_nlin = np.sqrt(mean_squared_error(y_test_nlin, pred_baseline_nlin))\n",
        "\n",
        "print('Baseline RMSE (não-linear):', round(rmse_baseline_nlin, 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 19 - treinar modelos no dataset não-linear\n",
        "# Lineares\n",
        "model_lr_b = LinearRegression().fit(X_train_nlin, y_train_nlin)\n",
        "model_ridge_b = Ridge(alpha=1.0, random_state=42).fit(X_train_nlin, y_train_nlin)\n",
        "model_en_b = ElasticNet(alpha=0.05, l1_ratio=0.5, random_state=42, max_iter=5000).fit(X_train_nlin, y_train_nlin)\n",
        "\n",
        "# Não-lineares\n",
        "model_tree_b = DecisionTreeRegressor(max_depth=4, random_state=42).fit(X_train_nlin, y_train_nlin)\n",
        "model_rf_b = RandomForestRegressor(n_estimators=300, max_depth=6, random_state=42).fit(X_train_nlin, y_train_nlin)\n",
        "model_gbm_b = GradientBoostingRegressor(random_state=42).fit(X_train_nlin, y_train_nlin)\n",
        "\n",
        "# Predições\n",
        "pred_lr_b = model_lr_b.predict(X_test_nlin)\n",
        "pred_ridge_b = model_ridge_b.predict(X_test_nlin)\n",
        "pred_en_b = model_en_b.predict(X_test_nlin)\n",
        "pred_tree_b = model_tree_b.predict(X_test_nlin)\n",
        "pred_rf_b = model_rf_b.predict(X_test_nlin)\n",
        "pred_gbm_b = model_gbm_b.predict(X_test_nlin)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 20 - métricas (PARTE B)\n",
        "results_b = pd.DataFrame([\n",
        "    {'modelo': 'Baseline_Naive', 'mae': mae_baseline_nlin, 'rmse': rmse_baseline_nlin},\n",
        "    {'modelo': 'LinearRegression', 'mae': mean_absolute_error(y_test_nlin, pred_lr_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_lr_b))},\n",
        "    {'modelo': 'Ridge', 'mae': mean_absolute_error(y_test_nlin, pred_ridge_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_ridge_b))},\n",
        "    {'modelo': 'ElasticNet', 'mae': mean_absolute_error(y_test_nlin, pred_en_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_en_b))},\n",
        "    {'modelo': 'DecisionTree', 'mae': mean_absolute_error(y_test_nlin, pred_tree_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_tree_b))},\n",
        "    {'modelo': 'RandomForest', 'mae': mean_absolute_error(y_test_nlin, pred_rf_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_rf_b))},\n",
        "    {'modelo': 'GradientBoosting', 'mae': mean_absolute_error(y_test_nlin, pred_gbm_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_gbm_b))},\n",
        "]).sort_values('rmse').reset_index(drop=True)\n",
        "\n",
        "results_b\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 21 - comparar melhor linear vs melhor não-linear (PARTE B)\n",
        "best_linear_b = results_b[results_b['modelo'].isin(['LinearRegression', 'Ridge', 'ElasticNet'])].iloc[0]['modelo']\n",
        "best_nonlinear_b = results_b[results_b['modelo'].isin(['DecisionTree', 'RandomForest', 'GradientBoosting'])].iloc[0]['modelo']\n",
        "\n",
        "pred_map_b = {\n",
        "    'LinearRegression': pred_lr_b,\n",
        "    'Ridge': pred_ridge_b,\n",
        "    'ElasticNet': pred_en_b,\n",
        "    'DecisionTree': pred_tree_b,\n",
        "    'RandomForest': pred_rf_b,\n",
        "    'GradientBoosting': pred_gbm_b,\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(11, 4))\n",
        "plt.plot(test_nlin['ds'], y_test_nlin.values, label='Real', color='black', linewidth=2)\n",
        "plt.plot(test_nlin['ds'], pred_map_b[best_linear_b], label=f'Melhor linear: {best_linear_b}', linewidth=1.8)\n",
        "plt.plot(test_nlin['ds'], pred_map_b[best_nonlinear_b], label=f'Melhor não-linear: {best_nonlinear_b}', linewidth=1.8)\n",
        "plt.title('PARTE B - Melhor linear vs melhor não-linear (teste)')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('y (R$ milhões)')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) PARTE C - Séries temporais (t -> y)\n",
        "\n",
        "### O que vamos fazer\n",
        "Comparar Baseline, ETS, ARIMA, ARIMAX e Prophet (opcional).\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Forecast de série temporal é comum quando o histórico já contém sinal forte.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 22 - carregar dataset de séries temporais\n",
        "url_ts = 'https://raw.githubusercontent.com/ian-iania/IBMEC-BV-Modelos-Preditivos/main/data/bv_fpa_timeseries.csv'\n",
        "\n",
        "df_ts = pd.read_csv(url_ts)\n",
        "df_ts['ds'] = pd.to_datetime(df_ts['ds'])\n",
        "\n",
        "df_ts.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 23 - plot da série\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(df_ts['ds'], df_ts['y'], linewidth=2)\n",
        "plt.title('PARTE C - Série temporal y')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('y (R$ milhões)')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 24 - split temporal (últimos 12 meses no teste)\n",
        "holdout = 12\n",
        "train_ts = df_ts.iloc[:-holdout].copy()\n",
        "test_ts = df_ts.iloc[-holdout:].copy()\n",
        "\n",
        "y_train_ts = train_ts['y'].values\n",
        "y_test_ts = test_ts['y'].values\n",
        "\n",
        "print('Treino:', train_ts.shape, 'Teste:', test_ts.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 25 - baseline naive\n",
        "pred_naive_ts = np.repeat(y_train_ts[-1], len(y_test_ts))\n",
        "mae_naive_ts = mean_absolute_error(y_test_ts, pred_naive_ts)\n",
        "rmse_naive_ts = np.sqrt(mean_squared_error(y_test_ts, pred_naive_ts))\n",
        "\n",
        "print('Baseline MAE :', round(mae_naive_ts, 3))\n",
        "print('Baseline RMSE:', round(rmse_naive_ts, 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 26 - ETS (Holt-Winters)\n",
        "ets = ExponentialSmoothing(train_ts['y'], trend='add', seasonal='add', seasonal_periods=12).fit(optimized=True)\n",
        "pred_ets = ets.forecast(len(test_ts)).values\n",
        "\n",
        "mae_ets = mean_absolute_error(y_test_ts, pred_ets)\n",
        "rmse_ets = np.sqrt(mean_squared_error(y_test_ts, pred_ets))\n",
        "\n",
        "print('ETS MAE :', round(mae_ets, 3))\n",
        "print('ETS RMSE:', round(rmse_ets, 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 27 - ARIMA\n",
        "arima = SARIMAX(train_ts['y'], order=(1, 1, 1), enforce_stationarity=False, enforce_invertibility=False).fit(disp=False)\n",
        "pred_arima = arima.forecast(steps=len(test_ts)).values\n",
        "\n",
        "mae_arima = mean_absolute_error(y_test_ts, pred_arima)\n",
        "rmse_arima = np.sqrt(mean_squared_error(y_test_ts, pred_arima))\n",
        "\n",
        "print('ARIMA MAE :', round(mae_arima, 3))\n",
        "print('ARIMA RMSE:', round(rmse_arima, 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 28 - ARIMAX (com selic)\n",
        "arimax = SARIMAX(\n",
        "    train_ts['y'],\n",
        "    exog=train_ts[['selic']],\n",
        "    order=(1, 1, 1),\n",
        "    enforce_stationarity=False,\n",
        "    enforce_invertibility=False\n",
        ").fit(disp=False)\n",
        "\n",
        "pred_arimax = arimax.forecast(steps=len(test_ts), exog=test_ts[['selic']]).values\n",
        "\n",
        "mae_arimax = mean_absolute_error(y_test_ts, pred_arimax)\n",
        "rmse_arimax = np.sqrt(mean_squared_error(y_test_ts, pred_arimax))\n",
        "\n",
        "print('ARIMAX MAE :', round(mae_arimax, 3))\n",
        "print('ARIMAX RMSE:', round(rmse_arimax, 3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Prophet (opcional)\n",
        "\n",
        "Se funcionar no ambiente, ótimo. Se não funcionar, siga com ETS/ARIMA/ARIMAX sem problema.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 29 (opcional) - instalar/importar Prophet\n",
        "import subprocess, sys\n",
        "prophet_ok = False\n",
        "\n",
        "try:\n",
        "    from prophet import Prophet\n",
        "    prophet_ok = True\n",
        "    print('Prophet já disponível.')\n",
        "except Exception:\n",
        "    print('Tentando instalar Prophet...')\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'prophet', '-q'])\n",
        "        from prophet import Prophet\n",
        "        prophet_ok = True\n",
        "        print('Prophet instalado com sucesso.')\n",
        "    except Exception as e:\n",
        "        print('Prophet indisponível nesta sessão.')\n",
        "        print('Erro:', e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 30 (opcional) - previsão com Prophet\n",
        "pred_prophet = None\n",
        "mae_prophet = None\n",
        "rmse_prophet = None\n",
        "\n",
        "if prophet_ok:\n",
        "    train_prophet = train_ts[['ds', 'y', 'selic', 'evento']].copy()\n",
        "    test_prophet = test_ts[['ds', 'selic', 'evento']].copy()\n",
        "\n",
        "    m = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)\n",
        "    m.add_regressor('selic')\n",
        "    m.add_regressor('evento')\n",
        "    m.fit(train_prophet)\n",
        "\n",
        "    fcst = m.predict(test_prophet)\n",
        "    pred_prophet = fcst['yhat'].values\n",
        "\n",
        "    mae_prophet = mean_absolute_error(y_test_ts, pred_prophet)\n",
        "    rmse_prophet = np.sqrt(mean_squared_error(y_test_ts, pred_prophet))\n",
        "\n",
        "    print('Prophet MAE :', round(mae_prophet, 3))\n",
        "    print('Prophet RMSE:', round(rmse_prophet, 3))\n",
        "else:\n",
        "    print('Prophet não executado.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 31 - tabela final PARTE C\n",
        "results_c = [\n",
        "    {'modelo': 'Baseline_Naive', 'mae': mae_naive_ts, 'rmse': rmse_naive_ts},\n",
        "    {'modelo': 'ETS_HoltWinters', 'mae': mae_ets, 'rmse': rmse_ets},\n",
        "    {'modelo': 'ARIMA', 'mae': mae_arima, 'rmse': rmse_arima},\n",
        "    {'modelo': 'ARIMAX_selic', 'mae': mae_arimax, 'rmse': rmse_arimax},\n",
        "]\n",
        "\n",
        "if pred_prophet is not None:\n",
        "    results_c.append({'modelo': 'Prophet', 'mae': mae_prophet, 'rmse': rmse_prophet})\n",
        "\n",
        "results_c = pd.DataFrame(results_c).sort_values('rmse').reset_index(drop=True)\n",
        "results_c\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 32 - gráfico final (real vs previsões)\n",
        "plt.figure(figsize=(11, 4))\n",
        "plt.plot(test_ts['ds'], y_test_ts, label='Real', color='black', linewidth=2)\n",
        "plt.plot(test_ts['ds'], pred_naive_ts, label='Baseline_Naive', linewidth=1.8)\n",
        "plt.plot(test_ts['ds'], pred_ets, label='ETS_HoltWinters', linewidth=1.8)\n",
        "plt.plot(test_ts['ds'], pred_arimax, label='ARIMAX_selic', linewidth=1.8)\n",
        "\n",
        "if pred_prophet is not None:\n",
        "    plt.plot(test_ts['ds'], pred_prophet, label='Prophet', linewidth=1.8)\n",
        "\n",
        "plt.title('PARTE C - Real vs Previsões (teste)')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('y (R$ milhões)')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Conclusão rápida\n",
        "\n",
        "- **X -> y (regressão):** melhor quando os drivers são conhecidos e úteis para cenário.\n",
        "- **t -> y (série temporal):** melhor quando o histórico da própria série é forte.\n",
        "- Em ambos os casos: validar no tempo e comparar com baseline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Checklist FP&A\n",
        "\n",
        "- Baseline: compare sempre com um método simples antes de escolher modelo.\n",
        "- Split temporal: treino no passado, teste no futuro (sem embaralhar).\n",
        "- Métricas: acompanhar MAE e RMSE em teste.\n",
        "- Governança: registrar versão do modelo, dados e período de treino.\n",
        "- Monitoramento: acompanhar performance e recalibrar quando necessário.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}