{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Logo BV IBMEC](https://raw.githubusercontent.com/ian-iania/IBMEC-BV-Modelos-Preditivos/main/logo-bv-ibmec-notebooks.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ian-iania/IBMEC-BV-Modelos-Preditivos/blob/main/notebooks/NB01_Regression.ipynb)\n",
        "\n",
        "# NB01 - Regressão e Séries Temporais (FP&A Banco BV)\n",
        "\n",
        "**Objetivo:** aplicar modelos de regressão e de séries temporais em dados sintéticos de FP&A do BV.\n",
        "**Você vai comparar baseline vs modelos, usando split temporal e métricas simples (MAE/RMSE).**\n",
        "**Foco em intuição de negócio: escolher modelo útil e robusto para apoiar decisão.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Setup do notebook\n",
        "\n",
        "### O que vamos fazer\n",
        "Importar bibliotecas e configurar funções utilitárias para reaproveitar o pipeline.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Padronizar o processo evita erros e facilita comparar modelos com critério.\n",
        "\n",
        "### O que você deve ver no output\n",
        "Pouca saída visual. Sem erro = ambiente pronto.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 1 - imports principais\n",
        "# Tabelas e operações numéricas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualização (sem seaborn, alinhado à aula)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Modelos de regressão\n",
        "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Métricas\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Modelos de séries temporais\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "\n",
        "# Utilitários de sistema\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 2 - função para carregar dataset com fallback\n",
        "# Ordem de tentativa:\n",
        "# 1) caminho relativo ../data/\n",
        "# 2) URL raw do GitHub\n",
        "# 3) upload manual no Colab\n",
        "\n",
        "def load_dataset(file_name: str) -> pd.DataFrame | None:\n",
        "    local_path = Path('../data') / file_name\n",
        "    if local_path.exists():\n",
        "        print(f'Carregando local: {local_path}')\n",
        "        return pd.read_csv(local_path)\n",
        "\n",
        "    raw_url = f'https://raw.githubusercontent.com/ian-iania/IBMEC-BV-Modelos-Preditivos/main/data/{file_name}'\n",
        "    try:\n",
        "        print(f'Carregando via GitHub raw: {raw_url}')\n",
        "        return pd.read_csv(raw_url)\n",
        "    except Exception as e:\n",
        "        print('Nao foi possivel carregar local/URL.')\n",
        "        print(f'Erro: {e}')\n",
        "        print('Use a celula de upload manual abaixo e rode novamente.')\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 3 (opcional) - upload manual de CSV no Colab\n",
        "# Use esta celula apenas se local/URL falharem.\n",
        "try:\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    print('Arquivos enviados:', list(uploaded.keys()))\n",
        "except Exception as e:\n",
        "    print('Upload manual disponivel apenas no Google Colab.')\n",
        "    print('Detalhe:', e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 4 - utilitários de split, métricas e treino\n",
        "# Split temporal (sem embaralhar): treino no passado, teste no futuro\n",
        "\n",
        "def temporal_split(df: pd.DataFrame, test_size: float = 0.2):\n",
        "    split_idx = int(len(df) * (1 - test_size))\n",
        "    train_df = df.iloc[:split_idx].copy()\n",
        "    test_df = df.iloc[split_idx:].copy()\n",
        "    return train_df, test_df\n",
        "\n",
        "# Métricas simples para comparar modelos\n",
        "\n",
        "def calc_metrics(y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    return mae, rmse\n",
        "\n",
        "# Treina e avalia uma lista de modelos de regressão\n",
        "\n",
        "def train_predict_evaluate(models_dict, X_train, y_train, X_test, y_test, baseline_value):\n",
        "    results = []\n",
        "    preds = {}\n",
        "    fitted = {}\n",
        "\n",
        "    # Baseline naive: repete ultimo valor observado do treino\n",
        "    y_pred_baseline = np.repeat(baseline_value, len(y_test))\n",
        "    mae_b, rmse_b = calc_metrics(y_test, y_pred_baseline)\n",
        "    results.append({'modelo': 'Baseline_Naive', 'mae': mae_b, 'rmse': rmse_b})\n",
        "    preds['Baseline_Naive'] = y_pred_baseline\n",
        "\n",
        "    # Modelos de ML\n",
        "    for name, model in models_dict.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        mae, rmse = calc_metrics(y_test, y_pred)\n",
        "        results.append({'modelo': name, 'mae': mae, 'rmse': rmse})\n",
        "        preds[name] = y_pred\n",
        "        fitted[name] = model\n",
        "\n",
        "    results_df = pd.DataFrame(results).sort_values('rmse', ascending=True).reset_index(drop=True)\n",
        "    return results_df, preds, fitted\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) PARTE A - Regressão com dataset linear (X -> y)\n",
        "\n",
        "### O que vamos fazer\n",
        "Treinar e comparar vários modelos no dataset linear.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Ajuda a entender quais drivers explicam melhor a originação e qual modelo tem melhor erro no futuro.\n",
        "\n",
        "### O que você deve ver no output\n",
        "Tabela de métricas (MAE/RMSE), gráficos de previsão e importâncias de variáveis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 5 - carregar dataset linear\n",
        "df_lin = load_dataset('bv_fpa_regressao_linear.csv')\n",
        "if df_lin is not None:\n",
        "    # Converte data e ordena para manter consistência temporal\n",
        "    df_lin['ds'] = pd.to_datetime(df_lin['ds'])\n",
        "    df_lin = df_lin.sort_values('ds').reset_index(drop=True)\n",
        "\n",
        "df_lin.head() if df_lin is not None else None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 6 - inspeção rápida (head, shape, dtypes)\n",
        "if df_lin is not None:\n",
        "    print('shape:', df_lin.shape)\n",
        "    print('\n",
        "Tipos de coluna:')\n",
        "    print(df_lin.dtypes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Visualizações rápidas (exploratórias)\n",
        "\n",
        "### O que vamos fazer\n",
        "Ver comportamento de `y` no tempo e relação simples entre `selic` e `y`.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Antes de modelar, é essencial enxergar tendência e possíveis relações entre variáveis.\n",
        "\n",
        "### O que você deve ver no output\n",
        "Um gráfico de linha e um gráfico de dispersão.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 7 - linha de y no tempo\n",
        "if df_lin is not None:\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(df_lin['ds'], df_lin['y'], color='#1f77b4', linewidth=2)\n",
        "    plt.title('Dataset linear - Originação (y) ao longo do tempo')\n",
        "    plt.xlabel('Data')\n",
        "    plt.ylabel('y (R$ milhões)')\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 8 - scatter selic vs y\n",
        "if df_lin is not None:\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.scatter(df_lin['selic'], df_lin['y'], alpha=0.75, color='#ff7f0e')\n",
        "    plt.title('Dataset linear - SELIC vs y')\n",
        "    plt.xlabel('SELIC')\n",
        "    plt.ylabel('y (R$ milhões)')\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Preparar X/y e split temporal\n",
        "\n",
        "### O que vamos fazer\n",
        "Separar variáveis explicativas (`X`) e alvo (`y`), depois dividir treino/teste no tempo (80/20).\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Em forecasting, o futuro não pode “vazar” para o treino.\n",
        "\n",
        "### O que você deve ver no output\n",
        "Tamanhos de treino e teste.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 9 - seleção de features e split temporal\n",
        "feature_cols = ['selic', 'desemprego', 'ltv_medio', 'spread', 'marketing', 'mix_auto', 'mes']\n",
        "\n",
        "a_train, a_test = temporal_split(df_lin, test_size=0.2)\n",
        "\n",
        "X_train_a = a_train[feature_cols]\n",
        "X_test_a = a_test[feature_cols]\n",
        "y_train_a = a_train['y']\n",
        "y_test_a = a_test['y']\n",
        "\n",
        "print('Treino:', X_train_a.shape, 'Teste:', X_test_a.shape)\n",
        "print('Periodo treino:', a_train['ds'].min().date(), '->', a_train['ds'].max().date())\n",
        "print('Periodo teste :', a_test['ds'].min().date(), '->', a_test['ds'].max().date())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Definir baseline e modelos\n",
        "\n",
        "### O que vamos fazer\n",
        "Comparar baseline naive e seis modelos de ML.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Se um modelo não supera baseline, ele não agrega valor de negócio.\n",
        "\n",
        "### O que você deve ver no output\n",
        "Lista de modelos e valor baseline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 10 - baseline e dicionário de modelos\n",
        "# Baseline naive: ultimo y do treino\n",
        "baseline_a = y_train_a.iloc[-1]\n",
        "print('Baseline (ultimo valor do treino):', round(float(baseline_a), 2))\n",
        "\n",
        "# Modelos (reprodutibilidade com random_state)\n",
        "models = {\n",
        "    'LinearRegression': Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', LinearRegression())\n",
        "    ]),\n",
        "    'Ridge': Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', Ridge(alpha=1.0, random_state=42))\n",
        "    ]),\n",
        "    'ElasticNet': Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', ElasticNet(alpha=0.05, l1_ratio=0.5, random_state=42, max_iter=5000))\n",
        "    ]),\n",
        "    'DecisionTree': DecisionTreeRegressor(max_depth=4, random_state=42),\n",
        "    'RandomForest': RandomForestRegressor(n_estimators=300, max_depth=6, random_state=42),\n",
        "    'GradientBoosting': GradientBoostingRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "print('Modelos prontos:', list(models.keys()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Treinar e avaliar no dataset linear\n",
        "\n",
        "### O que vamos fazer\n",
        "Treinar todos os modelos e comparar MAE/RMSE no teste.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Decisão de modelo deve ser baseada em erro fora da amostra (teste).\n",
        "\n",
        "### O que você deve ver no output\n",
        "Tabela ordenada por RMSE.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 11 - treino e avaliação (PARTE A)\n",
        "results_a, preds_a, fitted_a = train_predict_evaluate(\n",
        "    models_dict=models,\n",
        "    X_train=X_train_a,\n",
        "    y_train=y_train_a,\n",
        "    X_test=X_test_a,\n",
        "    y_test=y_test_a,\n",
        "    baseline_value=baseline_a\n",
        ")\n",
        "\n",
        "results_a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 12 - real vs previsto (baseline + 2 melhores)\n",
        "# Seleciona melhor linear e melhor geral para comparar com baseline\n",
        "linear_family = ['LinearRegression', 'Ridge', 'ElasticNet']\n",
        "\n",
        "best_linear_a = results_a[results_a['modelo'].isin(linear_family)].iloc[0]['modelo']\n",
        "best_overall_a = results_a[~results_a['modelo'].eq('Baseline_Naive')].iloc[0]['modelo']\n",
        "\n",
        "to_plot = ['Baseline_Naive', best_linear_a, best_overall_a]\n",
        "to_plot = list(dict.fromkeys(to_plot))\n",
        "\n",
        "plt.figure(figsize=(11, 4))\n",
        "plt.plot(a_test['ds'], y_test_a.values, label='Real', color='black', linewidth=2)\n",
        "for name in to_plot:\n",
        "    plt.plot(a_test['ds'], preds_a[name], label=name, linewidth=1.8)\n",
        "\n",
        "plt.title('PARTE A - Real vs Previsto (teste)')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('y (R$ milhões)')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print('Melhor linear:', best_linear_a)\n",
        "print('Melhor geral :', best_overall_a)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5 Feature importance (Random Forest e GBM)\n",
        "\n",
        "### O que vamos fazer\n",
        "Visualizar importância de variáveis em modelos de árvore.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Ajuda a priorizar drivers para discussão de negócio.\n",
        "\n",
        "### O que você deve ver no output\n",
        "Dois gráficos de barras de importância.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 13 - importância de variáveis (RandomForest)\n",
        "rf = fitted_a['RandomForest']\n",
        "rf_imp = pd.Series(rf.feature_importances_, index=feature_cols).sort_values(ascending=True)\n",
        "\n",
        "plt.figure(figsize=(7, 4))\n",
        "plt.barh(rf_imp.index, rf_imp.values, color='#2ca02c')\n",
        "plt.title('PARTE A - Feature importance (RandomForest)')\n",
        "plt.xlabel('Importância relativa')\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 14 - importância de variáveis (GradientBoosting)\n",
        "gbm = fitted_a['GradientBoosting']\n",
        "gbm_imp = pd.Series(gbm.feature_importances_, index=feature_cols).sort_values(ascending=True)\n",
        "\n",
        "plt.figure(figsize=(7, 4))\n",
        "plt.barh(gbm_imp.index, gbm_imp.values, color='#9467bd')\n",
        "plt.title('PARTE A - Feature importance (GradientBoosting)')\n",
        "plt.xlabel('Importância relativa')\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Nota importante:** importância de variável **não é causalidade**. Em dados com drivers correlacionados (ex.: `selic` e `spread`), interpretação deve ser feita com cuidado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) PARTE B - Mesmo pipeline no dataset não-linear\n",
        "\n",
        "### O que vamos fazer\n",
        "Repetir o pipeline no dataset com limiares/interações não-lineares.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Mostra na prática quando modelos não-lineares tendem a ganhar.\n",
        "\n",
        "### O que você deve ver no output\n",
        "Tabela de métricas e gráfico comparando melhor linear vs melhor não-linear.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 15 - carregar dataset não-linear\n",
        "df_nlin = load_dataset('bv_fpa_regressao_nonlinear.csv')\n",
        "if df_nlin is not None:\n",
        "    df_nlin['ds'] = pd.to_datetime(df_nlin['ds'])\n",
        "    df_nlin = df_nlin.sort_values('ds').reset_index(drop=True)\n",
        "\n",
        "df_nlin.head() if df_nlin is not None else None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 16 - split temporal e preparação de X/y (PARTE B)\n",
        "b_train, b_test = temporal_split(df_nlin, test_size=0.2)\n",
        "\n",
        "X_train_b = b_train[feature_cols]\n",
        "X_test_b = b_test[feature_cols]\n",
        "y_train_b = b_train['y']\n",
        "y_test_b = b_test['y']\n",
        "\n",
        "baseline_b = y_train_b.iloc[-1]\n",
        "print('Treino:', X_train_b.shape, 'Teste:', X_test_b.shape)\n",
        "print('Baseline B:', round(float(baseline_b), 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 17 - treino e métricas (PARTE B)\n",
        "results_b, preds_b, fitted_b = train_predict_evaluate(\n",
        "    models_dict=models,\n",
        "    X_train=X_train_b,\n",
        "    y_train=y_train_b,\n",
        "    X_test=X_test_b,\n",
        "    y_test=y_test_b,\n",
        "    baseline_value=baseline_b\n",
        ")\n",
        "\n",
        "results_b\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 18 - melhor linear vs melhor não-linear (PARTE B)\n",
        "linear_family = ['LinearRegression', 'Ridge', 'ElasticNet']\n",
        "nonlinear_family = ['DecisionTree', 'RandomForest', 'GradientBoosting']\n",
        "\n",
        "best_linear_b = results_b[results_b['modelo'].isin(linear_family)].iloc[0]['modelo']\n",
        "best_nonlinear_b = results_b[results_b['modelo'].isin(nonlinear_family)].iloc[0]['modelo']\n",
        "\n",
        "plt.figure(figsize=(11, 4))\n",
        "plt.plot(b_test['ds'], y_test_b.values, label='Real', color='black', linewidth=2)\n",
        "plt.plot(b_test['ds'], preds_b[best_linear_b], label=f'Linear: {best_linear_b}', linewidth=1.8)\n",
        "plt.plot(b_test['ds'], preds_b[best_nonlinear_b], label=f'Nao-linear: {best_nonlinear_b}', linewidth=1.8)\n",
        "\n",
        "plt.title('PARTE B - Melhor linear vs melhor não-linear (teste)')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('y (R$ milhões)')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print('Melhor linear B    :', best_linear_b)\n",
        "print('Melhor não-linear B:', best_nonlinear_b)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Leitura didática da PARTE B:** quando existem limiares, interações e não-linearidade, modelos de árvore/boosting costumam capturar melhor esses padrões.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) PARTE C - Séries temporais (t -> y)\n",
        "\n",
        "### O que vamos fazer\n",
        "Comparar Baseline, ETS, ARIMA, ARIMAX e Prophet (opcional) no dataset temporal.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Nem sempre teremos bons drivers explicativos; às vezes o próprio histórico de `y` já contém sinal forte.\n",
        "\n",
        "### O que você deve ver no output\n",
        "Tabela de MAE/RMSE no teste + conclusão de uso X->y vs t->y.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 19 - carregar dataset de séries temporais\n",
        "df_ts = load_dataset('bv_fpa_timeseries.csv')\n",
        "if df_ts is not None:\n",
        "    df_ts['ds'] = pd.to_datetime(df_ts['ds'])\n",
        "    df_ts = df_ts.sort_values('ds').reset_index(drop=True)\n",
        "\n",
        "df_ts.head() if df_ts is not None else None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 20 - plot da série y no tempo\n",
        "if df_ts is not None:\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(df_ts['ds'], df_ts['y'], color='#1f77b4', linewidth=2)\n",
        "    plt.title('PARTE C - Série temporal de y')\n",
        "    plt.xlabel('Data')\n",
        "    plt.ylabel('y (R$ milhões)')\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 21 - split temporal holdout final (12 meses)\n",
        "holdout = 12\n",
        "train_ts = df_ts.iloc[:-holdout].copy()\n",
        "test_ts = df_ts.iloc[-holdout:].copy()\n",
        "\n",
        "print('Treino TS:', train_ts.shape, 'Teste TS:', test_ts.shape)\n",
        "print('Periodo treino:', train_ts['ds'].min().date(), '->', train_ts['ds'].max().date())\n",
        "print('Periodo teste :', test_ts['ds'].min().date(), '->', test_ts['ds'].max().date())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 22 - baseline naive (ultimo valor observado)\n",
        "y_train_ts = train_ts['y'].values\n",
        "y_test_ts = test_ts['y'].values\n",
        "\n",
        "pred_naive_ts = np.repeat(y_train_ts[-1], len(y_test_ts))\n",
        "mae_naive_ts, rmse_naive_ts = calc_metrics(y_test_ts, pred_naive_ts)\n",
        "\n",
        "print('Baseline Naive - MAE :', round(mae_naive_ts, 3))\n",
        "print('Baseline Naive - RMSE:', round(rmse_naive_ts, 3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 ETS / Holt-Winters\n",
        "\n",
        "### O que vamos fazer\n",
        "Ajustar modelo com nível, tendência e sazonalidade.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Séries mensais frequentemente têm sazonalidade anual.\n",
        "\n",
        "### O que você deve ver no output\n",
        "Predição para o período de teste e métricas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 23 - ETS/Holt-Winters\n",
        "ets_model = ExponentialSmoothing(\n",
        "    train_ts['y'],\n",
        "    trend='add',\n",
        "    seasonal='add',\n",
        "    seasonal_periods=12\n",
        ").fit(optimized=True)\n",
        "\n",
        "pred_ets = ets_model.forecast(len(test_ts)).values\n",
        "mae_ets, rmse_ets = calc_metrics(y_test_ts, pred_ets)\n",
        "\n",
        "print('ETS - MAE :', round(mae_ets, 3))\n",
        "print('ETS - RMSE:', round(rmse_ets, 3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 ARIMA e ARIMAX\n",
        "\n",
        "### O que vamos fazer\n",
        "Treinar ARIMA puro e ARIMAX com `selic` como variável exógena.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "ARIMAX permite incorporar driver externo sem perder estrutura temporal.\n",
        "\n",
        "### O que você deve ver no output\n",
        "Métricas de ARIMA e ARIMAX.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 24 - ARIMA (sem exógena)\n",
        "arima_model = SARIMAX(\n",
        "    train_ts['y'],\n",
        "    order=(1, 1, 1),\n",
        "    enforce_stationarity=False,\n",
        "    enforce_invertibility=False\n",
        ").fit(disp=False)\n",
        "\n",
        "pred_arima = arima_model.forecast(steps=len(test_ts)).values\n",
        "mae_arima, rmse_arima = calc_metrics(y_test_ts, pred_arima)\n",
        "\n",
        "print('ARIMA - MAE :', round(mae_arima, 3))\n",
        "print('ARIMA - RMSE:', round(rmse_arima, 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 25 - ARIMAX (com selic exógena)\n",
        "arimax_model = SARIMAX(\n",
        "    train_ts['y'],\n",
        "    exog=train_ts[['selic']],\n",
        "    order=(1, 1, 1),\n",
        "    enforce_stationarity=False,\n",
        "    enforce_invertibility=False\n",
        ").fit(disp=False)\n",
        "\n",
        "pred_arimax = arimax_model.forecast(steps=len(test_ts), exog=test_ts[['selic']]).values\n",
        "mae_arimax, rmse_arimax = calc_metrics(y_test_ts, pred_arimax)\n",
        "\n",
        "print('ARIMAX - MAE :', round(mae_arimax, 3))\n",
        "print('ARIMAX - RMSE:', round(rmse_arimax, 3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Prophet (opcional)\n",
        "\n",
        "### O que vamos fazer\n",
        "Instalar e testar Prophet com regressoras opcionais (`selic`, `evento`).\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "É um modelo popular para forecast com sazonalidade e efeitos extras.\n",
        "\n",
        "### O que você deve ver no output\n",
        "Se disponível, métricas do Prophet. Se não, instruções claras.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 26 (opcional) - instalar/importar Prophet\n",
        "import importlib\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "prophet_ok = False\n",
        "\n",
        "try:\n",
        "    from prophet import Prophet\n",
        "    prophet_ok = True\n",
        "    print('Prophet já disponível no ambiente.')\n",
        "except Exception:\n",
        "    print('Prophet não encontrado. Tentando instalar (pode demorar)...')\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'prophet', '-q'])\n",
        "        from prophet import Prophet\n",
        "        prophet_ok = True\n",
        "        print('Prophet instalado com sucesso.')\n",
        "    except Exception as e:\n",
        "        print('Não foi possível instalar Prophet nesta sessão.')\n",
        "        print('Detalhe:', e)\n",
        "        print('Siga com ETS/ARIMA/ARIMAX normalmente.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 27 (opcional) - Prophet com regressoras selic e evento\n",
        "pred_prophet = None\n",
        "mae_prophet = None\n",
        "rmse_prophet = None\n",
        "\n",
        "if prophet_ok:\n",
        "    train_prophet = train_ts[['ds', 'y', 'selic', 'evento']].copy()\n",
        "    test_prophet = test_ts[['ds', 'selic', 'evento']].copy()\n",
        "\n",
        "    model_prophet = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)\n",
        "    model_prophet.add_regressor('selic')\n",
        "    model_prophet.add_regressor('evento')\n",
        "    model_prophet.fit(train_prophet)\n",
        "\n",
        "    forecast = model_prophet.predict(test_prophet)\n",
        "    pred_prophet = forecast['yhat'].values\n",
        "\n",
        "    mae_prophet, rmse_prophet = calc_metrics(y_test_ts, pred_prophet)\n",
        "    print('Prophet - MAE :', round(mae_prophet, 3))\n",
        "    print('Prophet - RMSE:', round(rmse_prophet, 3))\n",
        "else:\n",
        "    print('Prophet indisponível nesta execução.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 28 - tabela comparativa final (PARTE C)\n",
        "results_ts = [\n",
        "    {'modelo': 'Baseline_Naive', 'mae': mae_naive_ts, 'rmse': rmse_naive_ts},\n",
        "    {'modelo': 'ETS_HoltWinters', 'mae': mae_ets, 'rmse': rmse_ets},\n",
        "    {'modelo': 'ARIMA', 'mae': mae_arima, 'rmse': rmse_arima},\n",
        "    {'modelo': 'ARIMAX_selic', 'mae': mae_arimax, 'rmse': rmse_arimax},\n",
        "]\n",
        "\n",
        "if pred_prophet is not None:\n",
        "    results_ts.append({'modelo': 'Prophet', 'mae': mae_prophet, 'rmse': rmse_prophet})\n",
        "\n",
        "results_ts_df = pd.DataFrame(results_ts).sort_values('rmse').reset_index(drop=True)\n",
        "results_ts_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RUN_ME 29 - gráfico real vs modelos (PARTE C)\n",
        "plt.figure(figsize=(11, 4))\n",
        "plt.plot(test_ts['ds'], y_test_ts, label='Real', color='black', linewidth=2)\n",
        "plt.plot(test_ts['ds'], pred_naive_ts, label='Baseline_Naive', linewidth=1.8)\n",
        "plt.plot(test_ts['ds'], pred_arimax, label='ARIMAX_selic', linewidth=1.8)\n",
        "plt.plot(test_ts['ds'], pred_ets, label='ETS_HoltWinters', linewidth=1.8)\n",
        "\n",
        "if pred_prophet is not None:\n",
        "    plt.plot(test_ts['ds'], pred_prophet, label='Prophet', linewidth=1.8)\n",
        "\n",
        "plt.title('PARTE C - Real vs previsões (teste)')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('y (R$ milhões)')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Conclusão final\n",
        "\n",
        "### Quando usar X -> y (regressão)\n",
        "- Quando você tem drivers explicativos relevantes (macro, comercial, mix, risco).\n",
        "- Bom para simular cenários e impacto de decisões (ex.: marketing, spread, mix).\n",
        "\n",
        "### Quando usar t -> y (série temporal)\n",
        "- Quando o histórico da própria série já carrega padrão forte (tendência/sazonalidade).\n",
        "- Útil quando drivers são escassos, instáveis ou pouco confiáveis.\n",
        "\n",
        "### Ponto crítico para ambos\n",
        "- Sempre validar com **split temporal** e benchmark contra **baseline naive**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Checklist FP&A\n",
        "\n",
        "- Baseline: sempre comparar modelo com um baseline simples antes de “vender” ganho.\n",
        "- Split temporal: nunca embaralhar dados de tempo ao validar forecast.\n",
        "- Métricas: acompanhar MAE e RMSE no teste e monitorar estabilidade ao longo do tempo.\n",
        "- Governança: documentar versão do modelo, features usadas e data de treino.\n",
        "- Monitoramento: reavaliar performance periodicamente e re-treinar quando houver drift.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}