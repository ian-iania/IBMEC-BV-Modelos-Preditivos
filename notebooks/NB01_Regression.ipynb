{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Logo BV IBMEC](https://raw.githubusercontent.com/ian-iania/IBMEC-BV-Modelos-Preditivos/main/logo-bv-ibmec-notebooks.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ian-iania/IBMEC-BV-Modelos-Preditivos/blob/main/notebooks/NB01_Regression.ipynb)\n",
        "\n",
        "# NB01 - Regressão e Séries Temporais (FP&A Banco BV)\n",
        "\n",
        "**Objetivo:** aplicar regressão e séries temporais em dados sintéticos de FP&A do BV, com linguagem simples e foco em negócio.\n",
        "**Vamos comparar baseline e modelos com split temporal e métricas MAE/RMSE, em fluxo linear.**\n",
        "**A ideia é entender o processo sem exigir conhecimento prévio de programação.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Setup do notebook\n",
        "\n",
        "### O que vamos fazer\n",
        "Importar as bibliotecas da aula.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Sem essas bibliotecas não conseguimos carregar dados, treinar modelos e visualizar resultados.\n",
        "\n",
        "### O que você deve ver no output\n",
        "Sem erro na execução.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd  # biblioteca para carregar e manipular tabelas (DataFrames)\n",
        "import numpy as np  # biblioteca para operações numéricas\n",
        "import matplotlib.pyplot as plt  # biblioteca para criar gráficos\n",
        "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet  # modelos lineares\n",
        "from sklearn.tree import DecisionTreeRegressor  # modelo de árvore de decisão\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor  # modelos de ensemble baseados em árvores\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error  # métricas de avaliação MAE e RMSE\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing  # modelo ETS (Holt-Winters)\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX  # modelo ARIMA/ARIMAX\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1.1) Dois caminhos de previsão em FP&A: Supervisionados (X→Y) vs Séries temporais (t→Y)\n",
        "\n",
        "### ✅ Modelos supervisionados (X → Y)\n",
        "- Temos um alvo `y` (ex.: originação mensal) e drivers `X` (Selic, LTV, mix, marketing…).\n",
        "- O modelo aprende a relação **X → y** no histórico.\n",
        "- **Treino vs Teste (no tempo):** treinamos no passado e avaliamos no período futuro (o que FP&A realmente precisa).\n",
        "\n",
        "### ✅ Modelos de séries temporais (t → Y)\n",
        "- O principal driver é o **tempo**: tendência, sazonalidade e “memória” do histórico.\n",
        "- Algumas abordagens aceitam drivers externos (ex.: Selic) — isso aparece em **ARIMAX** (e pode aparecer no Prophet).\n",
        "\n",
        "> Mensagem FP&A: não existe “modelo melhor sempre”. Existe o melhor modelo para o padrão do dado e para o objetivo (forecast robusto e defendível).\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) PARTE A - Regressão com dataset linear (X -> y)\n",
        "\n",
        "### O que vamos fazer\n",
        "Carregar dataset linear, montar treino/teste e comparar baseline + modelos.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Esse tipo de modelo ajuda a explicar e prever a originação com base nos drivers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "url_linear = 'https://raw.githubusercontent.com/ian-iania/IBMEC-BV-Modelos-Preditivos/main/data/bv_fpa_regressao_linear.csv'  # URL do dataset linear\n",
        "df_lin = pd.read_csv(url_linear)  # leitura do CSV para DataFrame\n",
        "df_lin['ds'] = pd.to_datetime(df_lin['ds'])  # conversão da data para datetime\n",
        "df_lin.head()  # exibe as primeiras linhas da base\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Significado das colunas\n",
        "\n",
        "- `ds`: data de referência mensal (início do mês)\n",
        "- `y`: originação mensal em R$ milhões (**variável alvo**)\n",
        "- `selic`: taxa SELIC\n",
        "- `desemprego`: taxa de desemprego\n",
        "- `ltv_medio`: LTV médio\n",
        "- `spread`: spread médio\n",
        "- `marketing`: índice sintético de esforço comercial\n",
        "- `mix_auto`: participação de mix auto (0 a 1)\n",
        "- `mes`: mês numérico (1 a 12)\n",
        "\n",
        "Observação: `ds` e `y` são nomes comuns em modelagem (inclusive Prophet).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Inspeção da base (saídas separadas)\n",
        "\n",
        "Agora vamos checar tamanho, colunas e tipos em células separadas para não misturar output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_lin.shape  # mostra quantidade de linhas e colunas da base\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list(df_lin.columns)  # lista os nomes de todas as colunas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_lin.dtypes  # mostra o tipo de dado de cada coluna\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Visualização inicial\n",
        "\n",
        "### O que vamos fazer\n",
        "Ver `y` ao longo do tempo e `selic` versus `y`.\n",
        "\n",
        "### O que você deve ver no output\n",
        "Um gráfico de linha e um de dispersão.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 4))  # cria a figura do gráfico temporal\n",
        "plt.plot(df_lin['ds'], df_lin['y'], linewidth=2)  # plota y ao longo do tempo\n",
        "plt.title('PARTE A - Originação (y) ao longo do tempo')  # define o título\n",
        "plt.xlabel('Data')  # define eixo X\n",
        "plt.ylabel('y (R$ milhões)')  # define eixo Y\n",
        "plt.grid(alpha=0.3)  # adiciona grade\n",
        "plt.show()  # renderiza gráfico\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))  # cria a figura do gráfico de dispersão\n",
        "plt.scatter(df_lin['selic'], df_lin['y'], alpha=0.75)  # plota selic no eixo X e y no eixo Y\n",
        "plt.title('PARTE A - SELIC vs y')  # define título\n",
        "plt.xlabel('SELIC')  # define eixo X\n",
        "plt.ylabel('y (R$ milhões)')  # define eixo Y\n",
        "plt.grid(alpha=0.3)  # adiciona grade\n",
        "plt.show()  # renderiza gráfico\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Split temporal e baseline\n",
        "\n",
        "### O que vamos fazer\n",
        "Separar treino/teste no tempo (80%/20%, sem embaralhar) e calcular baseline naive.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "No mundo real, o modelo sempre prevê períodos futuros com base no passado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = ['selic', 'desemprego', 'ltv_medio', 'spread', 'marketing', 'mix_auto', 'mes']  # lista de variáveis explicativas\n",
        "split_idx = int(len(df_lin) * 0.8)  # define ponto de corte para treino e teste\n",
        "train_lin = df_lin.iloc[:split_idx].copy()  # seleciona linhas de treino\n",
        "train_lin = train_lin.sort_values('ds')  # garante ordenação temporal no treino\n",
        "test_lin = df_lin.iloc[split_idx:].copy()  # seleciona linhas de teste\n",
        "test_lin = test_lin.sort_values('ds')  # garante ordenação temporal no teste\n",
        "X_train_lin = train_lin[features]  # cria matriz X de treino\n",
        "X_test_lin = test_lin[features]  # cria matriz X de teste\n",
        "y_train_lin = train_lin['y']  # cria vetor y de treino\n",
        "y_test_lin = test_lin['y']  # cria vetor y de teste\n",
        "print('Treino:', X_train_lin.shape, 'Teste:', X_test_lin.shape)  # imprime tamanhos de treino e teste\n",
        "print('Período treino:', train_lin['ds'].min().date(), '->', train_lin['ds'].max().date())  # imprime intervalo de treino\n",
        "print('Período teste :', test_lin['ds'].min().date(), '->', test_lin['ds'].max().date())  # imprime intervalo de teste\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_value_lin = y_train_lin.iloc[-1]  # pega o último valor de y no treino\n",
        "pred_baseline_lin = np.repeat(baseline_value_lin, len(y_test_lin))  # repete esse valor para todo o teste\n",
        "mae_baseline_lin = mean_absolute_error(y_test_lin, pred_baseline_lin)  # calcula MAE do baseline\n",
        "rmse_baseline_lin = np.sqrt(mean_squared_error(y_test_lin, pred_baseline_lin))  # calcula RMSE do baseline\n",
        "print('Baseline MAE :', round(mae_baseline_lin, 3))  # imprime MAE\n",
        "print('Baseline RMSE:', round(rmse_baseline_lin, 3))  # imprime RMSE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5 Modelos de regressão (execução linear)\n",
        "\n",
        "Vamos treinar um modelo por vez, com uma célula de texto antes de cada treino.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo: LinearRegression\n",
        "\n",
        "**O que é:** regressão linear clássica; serve como baseline supervisionado simples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_lr = LinearRegression()  # cria o modelo de regressão linear\n",
        "model_lr.fit(X_train_lin, y_train_lin)  # treina o modelo\n",
        "pred_lr = model_lr.predict(X_test_lin)  # gera previsão no teste\n",
        "mae_lr = mean_absolute_error(y_test_lin, pred_lr)  # calcula MAE\n",
        "rmse_lr = np.sqrt(mean_squared_error(y_test_lin, pred_lr))  # calcula RMSE\n",
        "print('LinearRegression RMSE:', round(rmse_lr, 3))  # imprime RMSE do modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Por que esse resultado importa:** ele entra na comparação final em condições iguais de treino/teste.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo: Ridge\n",
        "\n",
        "**O que é:** regressão linear com regularização L2; ajuda estabilidade dos coeficientes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_ridge = Ridge(alpha=1.0, random_state=42)  # cria modelo Ridge\n",
        "model_ridge.fit(X_train_lin, y_train_lin)  # treina o Ridge\n",
        "pred_ridge = model_ridge.predict(X_test_lin)  # gera previsão no teste\n",
        "mae_ridge = mean_absolute_error(y_test_lin, pred_ridge)  # calcula MAE\n",
        "rmse_ridge = np.sqrt(mean_squared_error(y_test_lin, pred_ridge))  # calcula RMSE\n",
        "print('Ridge RMSE:', round(rmse_ridge, 3))  # imprime RMSE do modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Por que esse resultado importa:** ele entra na comparação final em condições iguais de treino/teste.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo: ElasticNet\n",
        "\n",
        "**O que é:** combina regularizações L1 e L2; útil com variáveis correlacionadas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_en = ElasticNet(alpha=0.05, l1_ratio=0.5, random_state=42, max_iter=5000)  # cria modelo ElasticNet\n",
        "model_en.fit(X_train_lin, y_train_lin)  # treina o ElasticNet\n",
        "pred_en = model_en.predict(X_test_lin)  # gera previsão no teste\n",
        "mae_en = mean_absolute_error(y_test_lin, pred_en)  # calcula MAE\n",
        "rmse_en = np.sqrt(mean_squared_error(y_test_lin, pred_en))  # calcula RMSE\n",
        "print('ElasticNet RMSE:', round(rmse_en, 3))  # imprime RMSE do modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Por que esse resultado importa:** ele entra na comparação final em condições iguais de treino/teste.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo: DecisionTree\n",
        "\n",
        "**O que é:** captura não-linearidades por regras de divisão.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_tree = DecisionTreeRegressor(max_depth=4, random_state=42)  # cria modelo de árvore\n",
        "model_tree.fit(X_train_lin, y_train_lin)  # treina árvore\n",
        "pred_tree = model_tree.predict(X_test_lin)  # gera previsão no teste\n",
        "mae_tree = mean_absolute_error(y_test_lin, pred_tree)  # calcula MAE\n",
        "rmse_tree = np.sqrt(mean_squared_error(y_test_lin, pred_tree))  # calcula RMSE\n",
        "print('DecisionTree RMSE:', round(rmse_tree, 3))  # imprime RMSE do modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Por que esse resultado importa:** ele entra na comparação final em condições iguais de treino/teste.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo: RandomForest\n",
        "\n",
        "**O que é:** ensemble de árvores; tende a reduzir variância e melhorar generalização.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_rf = RandomForestRegressor(n_estimators=300, max_depth=6, random_state=42)  # cria RandomForest\n",
        "model_rf.fit(X_train_lin, y_train_lin)  # treina RandomForest\n",
        "pred_rf = model_rf.predict(X_test_lin)  # gera previsão no teste\n",
        "mae_rf = mean_absolute_error(y_test_lin, pred_rf)  # calcula MAE\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test_lin, pred_rf))  # calcula RMSE\n",
        "print('RandomForest RMSE:', round(rmse_rf, 3))  # imprime RMSE do modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Por que esse resultado importa:** ele entra na comparação final em condições iguais de treino/teste.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo: GradientBoosting\n",
        "\n",
        "**O que é:** modelo de boosting que aprende correções sequenciais.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_gbm = GradientBoostingRegressor(random_state=42)  # cria modelo GradientBoosting\n",
        "model_gbm.fit(X_train_lin, y_train_lin)  # treina GradientBoosting\n",
        "pred_gbm = model_gbm.predict(X_test_lin)  # gera previsão no teste\n",
        "mae_gbm = mean_absolute_error(y_test_lin, pred_gbm)  # calcula MAE\n",
        "rmse_gbm = np.sqrt(mean_squared_error(y_test_lin, pred_gbm))  # calcula RMSE\n",
        "print('GradientBoosting RMSE:', round(rmse_gbm, 3))  # imprime RMSE do modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Por que esse resultado importa:** ele entra na comparação final em condições iguais de treino/teste.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### Teaser (ponte para Treino/Teste e comparação justa)\n",
        "“OK, eu medi MAE/RMSE… mas em qual dado? E como eu sei se isso vai funcionar no próximo trimestre?”\n",
        "\n",
        "Regras desta aula:\n",
        "- Comparação justa: todos os modelos usam o MESMO split temporal (mesmo TESTE).\n",
        "- Critério FP&A: escolhemos pelo desempenho no TESTE (MAE/RMSE), não pelo “passado perfeito”.\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.6 Tabela final e gráfico comparativo (PARTE A)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_a = pd.DataFrame([  # cria tabela de métricas da PARTE A\n",
        "    {'modelo': 'Baseline_Naive', 'mae': mae_baseline_lin, 'rmse': rmse_baseline_lin},  # baseline\n",
        "    {'modelo': 'LinearRegression', 'mae': mae_lr, 'rmse': rmse_lr},  # linear\n",
        "    {'modelo': 'Ridge', 'mae': mae_ridge, 'rmse': rmse_ridge},  # ridge\n",
        "    {'modelo': 'ElasticNet', 'mae': mae_en, 'rmse': rmse_en},  # elasticnet\n",
        "    {'modelo': 'DecisionTree', 'mae': mae_tree, 'rmse': rmse_tree},  # árvore\n",
        "    {'modelo': 'RandomForest', 'mae': mae_rf, 'rmse': rmse_rf},  # random forest\n",
        "    {'modelo': 'GradientBoosting', 'mae': mae_gbm, 'rmse': rmse_gbm},  # gradient boosting\n",
        "]).sort_values('rmse').reset_index(drop=True)  # ordena por melhor RMSE\n",
        "results_a  # exibe ranking final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_linear_name = results_a[results_a['modelo'].isin(['LinearRegression', 'Ridge', 'ElasticNet'])].iloc[0]['modelo']  # seleciona melhor linear\n",
        "best_nonlinear_name = results_a[results_a['modelo'].isin(['DecisionTree', 'RandomForest', 'GradientBoosting'])].iloc[0]['modelo']  # seleciona melhor não-linear\n",
        "pred_map_a = {  # dicionário com previsões da PARTE A\n",
        "    'LinearRegression': pred_lr,  # previsões linear\n",
        "    'Ridge': pred_ridge,  # previsões ridge\n",
        "    'ElasticNet': pred_en,  # previsões elasticnet\n",
        "    'DecisionTree': pred_tree,  # previsões árvore\n",
        "    'RandomForest': pred_rf,  # previsões random forest\n",
        "    'GradientBoosting': pred_gbm,  # previsões gradient boosting\n",
        "}  # fim do dicionário\n",
        "plt.figure(figsize=(11, 4))  # cria figura para comparação de previsões\n",
        "plt.plot(test_lin['ds'], y_test_lin.values, label='Real', color='black', linewidth=2)  # linha real\n",
        "plt.plot(test_lin['ds'], pred_baseline_lin, label='Baseline_Naive', linewidth=1.8)  # linha baseline\n",
        "plt.plot(test_lin['ds'], pred_map_a[best_linear_name], label=f'Melhor linear: {best_linear_name}', linewidth=1.8)  # linha melhor linear\n",
        "plt.plot(test_lin['ds'], pred_map_a[best_nonlinear_name], label=f'Melhor não-linear: {best_nonlinear_name}', linewidth=1.8)  # linha melhor não-linear\n",
        "plt.title('PARTE A - Real vs Previsto (teste)')  # título do gráfico\n",
        "plt.xlabel('Data')  # eixo X\n",
        "plt.ylabel('y (R$ milhões)')  # eixo Y\n",
        "plt.legend()  # legenda\n",
        "plt.grid(alpha=0.3)  # grade\n",
        "plt.show()  # renderiza gráfico\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model_a = results_a.sort_values('rmse').iloc[0]['modelo']  # identifica o melhor modelo da PARTE A pelo menor RMSE\n",
        "if best_model_a == 'Baseline_Naive':  # trata o caso em que o baseline seja o melhor\n",
        "    pred_best_a = pred_baseline_lin  # usa previsão do baseline como melhor previsão\n",
        "else:  # quando o melhor modelo não é o baseline\n",
        "    pred_best_a = pred_map_a.get(best_model_a, None)  # busca as previsões do melhor modelo no dicionário\n",
        "\n",
        "plt.figure(figsize=(11, 3.8))  # cria figura do erro absoluto por mês\n",
        "plt.plot(test_lin['ds'], np.abs(y_test_lin - pred_baseline_lin), label='Erro abs - Baseline_Naive', linewidth=2)  # erro absoluto do baseline\n",
        "if pred_best_a is not None:  # plota somente se houver previsão válida do melhor modelo\n",
        "    plt.plot(test_lin['ds'], np.abs(y_test_lin - pred_best_a), label=f'Erro abs - {best_model_a}', linewidth=2)  # erro absoluto do melhor modelo\n",
        "plt.title('PARTE A - Erro absoluto por mês (no TESTE)')  # define título do gráfico\n",
        "plt.xlabel('Mês')  # define eixo X\n",
        "plt.ylabel('|Erro| (unidade de y)')  # define eixo Y\n",
        "plt.legend()  # adiciona legenda\n",
        "plt.tight_layout()  # ajusta layout\n",
        "plt.show()  # renderiza gráfico\n",
        "print('Leitura FP&A: picos de erro indicam meses com choque/sazonalidade/mudança de regime que merecem investigação.')  # interpretação de negócio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5.5, 5.0))  # cria figura do scatter Predito vs Real\n",
        "plt.scatter(y_test_lin, pred_best_a, alpha=0.7)  # plota valores reais contra valores preditos\n",
        "plt.title(f'PARTE A - Predito vs Real (TESTE) | {best_model_a}')  # define título com nome do melhor modelo\n",
        "plt.xlabel('Real (y)')  # define eixo X\n",
        "plt.ylabel('Predito (ŷ)')  # define eixo Y\n",
        "minv = min(y_test_lin.min(), pred_best_a.min())  # menor valor para linha de referência\n",
        "maxv = max(y_test_lin.max(), pred_best_a.max())  # maior valor para linha de referência\n",
        "plt.plot([minv, maxv], [minv, maxv], linewidth=2)  # desenha diagonal y=x\n",
        "plt.tight_layout()  # ajusta layout\n",
        "plt.show()  # renderiza gráfico\n",
        "print('Leitura FP&A: quanto mais perto da diagonal, melhor o modelo no período de TESTE.')  # interpretação de negócio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resid_a = y_test_lin - pred_best_a  # calcula resíduos da PARTE A (Real - Predito)\n",
        "plt.figure(figsize=(7.5, 3.8))  # cria figura do histograma de resíduos\n",
        "plt.hist(resid_a, bins=18, alpha=0.8)  # plota distribuição dos resíduos\n",
        "plt.title(f'PARTE A - Resíduos no TESTE | {best_model_a} (Real - Predito)')  # define título\n",
        "plt.xlabel('Resíduo')  # define eixo X\n",
        "plt.ylabel('Frequência')  # define eixo Y\n",
        "plt.tight_layout()  # ajusta layout\n",
        "plt.show()  # renderiza gráfico\n",
        "print('Leitura FP&A: resíduos muito assimétricos ou com caudas grandes sugerem regime/driver faltando ou não-linearidade.')  # interpretação de negócio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.7 Feature importance (introdução)\n",
        "\n",
        "### O que vamos fazer\n",
        "Medir importância das variáveis para RandomForest e GradientBoosting.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Ajuda a priorizar quais drivers merecem atenção na discussão gerencial.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### Como a Feature Importance é calculada (explicação simples)\n",
        "\n",
        "Em modelos de árvore (DecisionTree / RandomForest / GradientBoosting), a **feature importance** costuma ser calculada assim:\n",
        "\n",
        "- Cada split do tipo “se X > valor” reduz o erro do modelo naquele nó.\n",
        "- A importância de uma variável mede **quanto ela contribuiu para reduzir o erro** ao longo dos splits.\n",
        "- No scikit-learn, a importância é a soma da **redução do critério** (ex.: MSE) atribuída à variável em todos os splits, agregada no conjunto de árvores (RF/GBM) e normalizada para somar 1.\n",
        "\n",
        "✅ O que representa:\n",
        "- Um **ranking de utilidade para previsão**: quais drivers mais ajudaram a diminuir o erro.\n",
        "\n",
        "⚠️ O que NÃO representa:\n",
        "- **Causalidade**. Importância alta não prova que “X causa Y”.\n",
        "- Se duas variáveis são correlacionadas (ex.: Selic e spread), a importância pode “migrar” de uma para outra.\n",
        "\n",
        "> Mensagem FP&A: use importance como bússola para priorizar drivers e conversas, e valide com lógica de negócio.\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_imp = pd.Series(model_rf.feature_importances_, index=features).sort_values(ascending=True)  # calcula importâncias do RandomForest\n",
        "gbm_imp = pd.Series(model_gbm.feature_importances_, index=features).sort_values(ascending=True)  # calcula importâncias do GradientBoosting\n",
        "rf_imp  # exibe vetor de importâncias do RandomForest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))  # cria figura do RandomForest\n",
        "plt.barh(rf_imp.index, rf_imp.values)  # plota barras horizontais do RandomForest\n",
        "plt.title('Importância - RandomForest')  # define título do gráfico\n",
        "plt.grid(axis='x', alpha=0.3)  # adiciona grade horizontal\n",
        "plt.show()  # renderiza gráfico\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))  # cria figura do GradientBoosting\n",
        "plt.barh(gbm_imp.index, gbm_imp.values)  # plota barras horizontais do GradientBoosting\n",
        "plt.title('Importância - GradientBoosting')  # define título do gráfico\n",
        "plt.grid(axis='x', alpha=0.3)  # adiciona grade horizontal\n",
        "plt.show()  # renderiza gráfico\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) PARTE B - Mesmo pipeline no dataset não-linear\n",
        "\n",
        "### O que vamos fazer\n",
        "Repetir o fluxo no dataset não-linear.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Em cenários com limiares/interações, modelos não-lineares tendem a capturar melhor os padrões.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Carregar base não-linear e visualizar padrão\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "url_nlin = 'https://raw.githubusercontent.com/ian-iania/IBMEC-BV-Modelos-Preditivos/main/data/bv_fpa_regressao_nonlinear.csv'  # URL da base não-linear\n",
        "df_nlin = pd.read_csv(url_nlin)  # leitura da base não-linear\n",
        "df_nlin['ds'] = pd.to_datetime(df_nlin['ds'])  # conversão da data para datetime\n",
        "df_nlin.head()  # exibe primeiras linhas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 4))  # cria figura para série da PARTE B\n",
        "plt.plot(df_nlin['ds'], df_nlin['y'], linewidth=2)  # plota y ao longo do tempo na base não-linear\n",
        "plt.title('PARTE B - Originação (y) ao longo do tempo')  # define título\n",
        "plt.xlabel('Data')  # define eixo X\n",
        "plt.ylabel('y (R$ milhões)')  # define eixo Y\n",
        "plt.grid(alpha=0.3)  # adiciona grade\n",
        "plt.show()  # renderiza gráfico\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### Visualizando o “regime” não-linear (por que árvores podem ganhar aqui)\n",
        "No dataset não-linear, existe um comportamento por faixas (limiar). Vamos marcar um “regime” para visualizar onde o padrão muda.\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "threshold = 9.5  # define limiar de SELIC para separar regimes\n",
        "df_nl = df_nlin.copy()  # cria cópia da base não-linear para análise de regime\n",
        "df_nl['regime_selic'] = (df_nl['selic'] > threshold).astype(int)  # cria indicador 0/1 para o regime de SELIC\n",
        "\n",
        "plt.figure(figsize=(7.8, 4.2))  # cria figura do scatter por regime\n",
        "for r in [0, 1]:  # percorre os dois regimes (baixo e alto)\n",
        "    sub = df_nl[df_nl['regime_selic'] == r]  # filtra dados do regime atual\n",
        "    label = f'Selic <= {threshold}' if r == 0 else f'Selic > {threshold}'  # cria rótulo do regime\n",
        "    plt.scatter(sub['selic'], sub['y'], alpha=0.7, label=label)  # plota pontos do regime atual\n",
        "plt.title('PARTE B - Scatter Selic vs y (colorido por regime)')  # define título\n",
        "plt.xlabel('Selic')  # define eixo X\n",
        "plt.ylabel('y (originação)')  # define eixo Y\n",
        "plt.legend()  # exibe legenda por regime\n",
        "plt.tight_layout()  # ajusta layout\n",
        "plt.show()  # renderiza gráfico\n",
        "\n",
        "print('Leitura FP&A: se os pontos formam padrões diferentes por faixa, uma reta única tende a errar mais — árvores/GBM capturam melhor limiares e interações.')  # interpretação de negócio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Split temporal e baseline (PARTE B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_idx_b = int(len(df_nlin) * 0.8)  # define ponto de corte de treino/teste\n",
        "train_nlin = df_nlin.iloc[:split_idx_b].copy()  # recorte de treino da base não-linear\n",
        "train_nlin = train_nlin.sort_values('ds')  # garante ordenação temporal de treino\n",
        "test_nlin = df_nlin.iloc[split_idx_b:].copy()  # recorte de teste da base não-linear\n",
        "test_nlin = test_nlin.sort_values('ds')  # garante ordenação temporal de teste\n",
        "X_train_nlin = train_nlin[features]  # monta X de treino\n",
        "X_test_nlin = test_nlin[features]  # monta X de teste\n",
        "y_train_nlin = train_nlin['y']  # monta y de treino\n",
        "y_test_nlin = test_nlin['y']  # monta y de teste\n",
        "\n",
        "# aliases para facilitar leitura nos gráficos extras solicitados\n",
        "X_train_nl = X_train_nlin  # alias do X treino\n",
        "X_test_nl = X_test_nlin  # alias do X teste\n",
        "y_train_nl = y_train_nlin  # alias do y treino\n",
        "y_test_nl = y_test_nlin  # alias do y teste\n",
        "test_nl = test_nlin  # alias do DataFrame de teste\n",
        "\n",
        "baseline_value_nlin = y_train_nlin.iloc[-1]  # captura último valor de treino para baseline\n",
        "pred_baseline_nlin = np.repeat(baseline_value_nlin, len(y_test_nlin))  # gera previsão baseline\n",
        "pred_baseline_nl = pred_baseline_nlin  # alias da previsão baseline\n",
        "mae_baseline_nlin = mean_absolute_error(y_test_nlin, pred_baseline_nlin)  # calcula MAE do baseline\n",
        "rmse_baseline_nlin = np.sqrt(mean_squared_error(y_test_nlin, pred_baseline_nlin))  # calcula RMSE do baseline\n",
        "print('Baseline RMSE (não-linear):', round(rmse_baseline_nlin, 3))  # imprime RMSE baseline da PARTE B\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### Mini-experimento: profundidade da árvore e overfitting (treino vs teste)\n",
        "Uma árvore muito profunda pode “decorar” o histórico. Vamos ver o efeito da profundidade no erro de treino e teste.\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "depths = list(range(1, 16))  # define profundidades a testar\n",
        "rmse_train, rmse_test = [], []  # inicializa listas de erro de treino e teste\n",
        "\n",
        "for d in depths:  # testa cada profundidade\n",
        "    m = DecisionTreeRegressor(max_depth=d, random_state=42)  # cria árvore com profundidade d\n",
        "    m.fit(X_train_nl, y_train_nl)  # treina árvore\n",
        "    pred_tr = m.predict(X_train_nl)  # prevê no treino\n",
        "    pred_te = m.predict(X_test_nl)  # prevê no teste\n",
        "    rmse_train.append(np.sqrt(mean_squared_error(y_train_nl, pred_tr)))  # guarda RMSE treino\n",
        "    rmse_test.append(np.sqrt(mean_squared_error(y_test_nl, pred_te)))  # guarda RMSE teste\n",
        "\n",
        "plt.figure(figsize=(9.2, 3.8))  # cria figura do experimento\n",
        "plt.plot(depths, rmse_train, label='RMSE Treino', linewidth=2)  # plota curva de treino\n",
        "plt.plot(depths, rmse_test, label='RMSE Teste', linewidth=2)  # plota curva de teste\n",
        "plt.title('PARTE B - Overfitting em árvore: RMSE vs profundidade')  # define título\n",
        "plt.xlabel('max_depth')  # define eixo X\n",
        "plt.ylabel('RMSE')  # define eixo Y\n",
        "plt.legend()  # exibe legenda\n",
        "plt.tight_layout()  # ajusta layout\n",
        "plt.show()  # renderiza gráfico\n",
        "\n",
        "print('Leitura FP&A: quando o RMSE de treino cai muito e o de teste sobe, é overfitting (o modelo decorou o passado).')  # interpretação de negócio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Treinar modelos na base não-linear\n",
        "\n",
        "Vamos repetir os mesmos modelos da PARTE A para comparação justa.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo: LinearRegression (PARTE B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_lr_b = LinearRegression()  # cria LinearRegression da PARTE B\n",
        "model_lr_b.fit(X_train_nlin, y_train_nlin)  # treina LinearRegression na base não-linear\n",
        "pred_lr_b = model_lr_b.predict(X_test_nlin)  # gera previsão da LinearRegression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo: Ridge (PARTE B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_ridge_b = Ridge(alpha=1.0, random_state=42)  # cria Ridge da PARTE B\n",
        "model_ridge_b.fit(X_train_nlin, y_train_nlin)  # treina Ridge na base não-linear\n",
        "pred_ridge_b = model_ridge_b.predict(X_test_nlin)  # gera previsão do Ridge\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo: ElasticNet (PARTE B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_en_b = ElasticNet(alpha=0.05, l1_ratio=0.5, random_state=42, max_iter=5000)  # cria ElasticNet da PARTE B\n",
        "model_en_b.fit(X_train_nlin, y_train_nlin)  # treina ElasticNet na base não-linear\n",
        "pred_en_b = model_en_b.predict(X_test_nlin)  # gera previsão do ElasticNet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo: DecisionTree (PARTE B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_tree_b = DecisionTreeRegressor(max_depth=4, random_state=42)  # cria árvore da PARTE B\n",
        "model_tree_b.fit(X_train_nlin, y_train_nlin)  # treina árvore da PARTE B\n",
        "pred_tree_b = model_tree_b.predict(X_test_nlin)  # gera previsão da árvore\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo: RandomForest (PARTE B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_rf_b = RandomForestRegressor(n_estimators=300, max_depth=6, random_state=42)  # cria RandomForest da PARTE B\n",
        "model_rf_b.fit(X_train_nlin, y_train_nlin)  # treina RandomForest da PARTE B\n",
        "pred_rf_b = model_rf_b.predict(X_test_nlin)  # gera previsão do RandomForest\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo: GradientBoosting (PARTE B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_gbm_b = GradientBoostingRegressor(random_state=42)  # cria GradientBoosting da PARTE B\n",
        "model_gbm_b.fit(X_train_nlin, y_train_nlin)  # treina GradientBoosting da PARTE B\n",
        "pred_gbm_b = model_gbm_b.predict(X_test_nlin)  # gera previsão do GradientBoosting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Tabela de métricas (PARTE B)\n",
        "\n",
        "Agora comparamos MAE/RMSE de todos os modelos no mesmo TESTE da PARTE B.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Garantia para evitar NameError se alguma célula de treino tiver sido pulada\n",
        "if 'pred_lr_b' not in globals():  # verifica se previsões da PARTE B existem\n",
        "    model_lr_b = LinearRegression()  # recria LinearRegression da PARTE B\n",
        "    model_lr_b.fit(X_train_nlin, y_train_nlin)  # retreina LinearRegression da PARTE B\n",
        "    pred_lr_b = model_lr_b.predict(X_test_nlin)  # regenera previsão da LinearRegression da PARTE B\n",
        "if 'pred_ridge_b' not in globals():  # verifica previsão do Ridge na PARTE B\n",
        "    model_ridge_b = Ridge(alpha=1.0, random_state=42)  # recria Ridge da PARTE B\n",
        "    model_ridge_b.fit(X_train_nlin, y_train_nlin)  # retreina Ridge da PARTE B\n",
        "    pred_ridge_b = model_ridge_b.predict(X_test_nlin)  # regenera previsão do Ridge da PARTE B\n",
        "if 'pred_en_b' not in globals():  # verifica previsão do ElasticNet na PARTE B\n",
        "    model_en_b = ElasticNet(alpha=0.05, l1_ratio=0.5, random_state=42, max_iter=5000)  # recria ElasticNet da PARTE B\n",
        "    model_en_b.fit(X_train_nlin, y_train_nlin)  # retreina ElasticNet da PARTE B\n",
        "    pred_en_b = model_en_b.predict(X_test_nlin)  # regenera previsão do ElasticNet da PARTE B\n",
        "if 'pred_tree_b' not in globals():  # verifica previsão da árvore na PARTE B\n",
        "    model_tree_b = DecisionTreeRegressor(max_depth=4, random_state=42)  # recria árvore da PARTE B\n",
        "    model_tree_b.fit(X_train_nlin, y_train_nlin)  # retreina árvore da PARTE B\n",
        "    pred_tree_b = model_tree_b.predict(X_test_nlin)  # regenera previsão da árvore da PARTE B\n",
        "if 'pred_rf_b' not in globals():  # verifica previsão do RandomForest na PARTE B\n",
        "    model_rf_b = RandomForestRegressor(n_estimators=300, max_depth=6, random_state=42)  # recria RandomForest da PARTE B\n",
        "    model_rf_b.fit(X_train_nlin, y_train_nlin)  # retreina RandomForest da PARTE B\n",
        "    pred_rf_b = model_rf_b.predict(X_test_nlin)  # regenera previsão do RandomForest da PARTE B\n",
        "if 'pred_gbm_b' not in globals():  # verifica previsão do GradientBoosting na PARTE B\n",
        "    model_gbm_b = GradientBoostingRegressor(random_state=42)  # recria GradientBoosting da PARTE B\n",
        "    model_gbm_b.fit(X_train_nlin, y_train_nlin)  # retreina GradientBoosting da PARTE B\n",
        "    pred_gbm_b = model_gbm_b.predict(X_test_nlin)  # regenera previsão do GradientBoosting da PARTE B\n",
        "\n",
        "results_b = pd.DataFrame([  # cria tabela de resultados da PARTE B\n",
        "    {'modelo': 'Baseline_Naive', 'mae': mae_baseline_nlin, 'rmse': rmse_baseline_nlin},  # linha baseline\n",
        "    {'modelo': 'LinearRegression', 'mae': mean_absolute_error(y_test_nlin, pred_lr_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_lr_b))},  # linha linear\n",
        "    {'modelo': 'Ridge', 'mae': mean_absolute_error(y_test_nlin, pred_ridge_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_ridge_b))},  # linha ridge\n",
        "    {'modelo': 'ElasticNet', 'mae': mean_absolute_error(y_test_nlin, pred_en_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_en_b))},  # linha elasticnet\n",
        "    {'modelo': 'DecisionTree', 'mae': mean_absolute_error(y_test_nlin, pred_tree_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_tree_b))},  # linha árvore\n",
        "    {'modelo': 'RandomForest', 'mae': mean_absolute_error(y_test_nlin, pred_rf_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_rf_b))},  # linha random forest\n",
        "    {'modelo': 'GradientBoosting', 'mae': mean_absolute_error(y_test_nlin, pred_gbm_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_gbm_b))},  # linha gradient boosting\n",
        "]).sort_values('rmse').reset_index(drop=True)  # ordena por melhor RMSE\n",
        "results_b  # exibe ranking final da PARTE B\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.5 Gráfico comparativo (PARTE B)\n",
        "\n",
        "Vamos comparar visualmente o melhor modelo linear versus o melhor não-linear.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_linear_b = results_b[results_b['modelo'].isin(['LinearRegression', 'Ridge', 'ElasticNet'])].iloc[0]['modelo']  # identifica melhor linear da PARTE B\n",
        "best_nonlinear_b = results_b[results_b['modelo'].isin(['DecisionTree', 'RandomForest', 'GradientBoosting'])].iloc[0]['modelo']  # identifica melhor não-linear da PARTE B\n",
        "pred_map_b = {  # cria dicionário de previsões da PARTE B\n",
        "    'LinearRegression': pred_lr_b,  # previsão LinearRegression\n",
        "    'Ridge': pred_ridge_b,  # previsão Ridge\n",
        "    'ElasticNet': pred_en_b,  # previsão ElasticNet\n",
        "    'DecisionTree': pred_tree_b,  # previsão DecisionTree\n",
        "    'RandomForest': pred_rf_b,  # previsão RandomForest\n",
        "    'GradientBoosting': pred_gbm_b,  # previsão GradientBoosting\n",
        "}  # fim do dicionário\n",
        "plt.figure(figsize=(11, 4))  # cria figura comparativa da PARTE B\n",
        "plt.plot(test_nlin['ds'], y_test_nlin.values, label='Real', color='black', linewidth=2)  # plota série real\n",
        "plt.plot(test_nlin['ds'], pred_map_b[best_linear_b], label=f'Melhor linear: {best_linear_b}', linewidth=1.8)  # plota melhor linear\n",
        "plt.plot(test_nlin['ds'], pred_map_b[best_nonlinear_b], label=f'Melhor não-linear: {best_nonlinear_b}', linewidth=1.8)  # plota melhor não-linear\n",
        "plt.title('PARTE B - Melhor linear vs melhor não-linear (teste)')  # define título\n",
        "plt.xlabel('Data')  # define eixo X\n",
        "plt.ylabel('y (R$ milhões)')  # define eixo Y\n",
        "plt.legend()  # exibe legenda\n",
        "plt.grid(alpha=0.3)  # adiciona grade\n",
        "plt.show()  # renderiza gráfico\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model_b = results_b.sort_values('rmse').iloc[0]['modelo']  # identifica melhor modelo da PARTE B pelo menor RMSE\n",
        "if best_model_b == 'Baseline_Naive':  # trata caso do baseline ser o melhor\n",
        "    pred_best_b = pred_baseline_nlin  # usa baseline como melhor previsão\n",
        "else:  # caso modelo vencedor seja de ML\n",
        "    pred_best_b = pred_map_b.get(best_model_b, None)  # busca previsões do melhor modelo\n",
        "\n",
        "plt.figure(figsize=(11, 3.8))  # cria figura do erro absoluto da PARTE B\n",
        "plt.plot(test_nl['ds'], np.abs(y_test_nl - pred_baseline_nl), label='Erro abs - Baseline_Naive', linewidth=2)  # erro baseline\n",
        "if pred_best_b is not None:  # plota erro do melhor modelo quando disponível\n",
        "    plt.plot(test_nl['ds'], np.abs(y_test_nl - pred_best_b), label=f'Erro abs - {best_model_b}', linewidth=2)  # erro melhor modelo\n",
        "plt.title('PARTE B - Erro absoluto por mês (no TESTE)')  # define título\n",
        "plt.xlabel('Mês')  # define eixo X\n",
        "plt.ylabel('|Erro| (unidade de y)')  # define eixo Y\n",
        "plt.legend()  # exibe legenda\n",
        "plt.tight_layout()  # ajusta layout\n",
        "plt.show()  # renderiza gráfico\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5.5, 5.0))  # cria figura do scatter Predito vs Real da PARTE B\n",
        "plt.scatter(y_test_nl, pred_best_b, alpha=0.7)  # plota valores reais versus preditos\n",
        "plt.title(f'PARTE B - Predito vs Real (TESTE) | {best_model_b}')  # define título\n",
        "plt.xlabel('Real (y)')  # define eixo X\n",
        "plt.ylabel('Predito (ŷ)')  # define eixo Y\n",
        "minv = min(y_test_nl.min(), pred_best_b.min())  # define mínimo para diagonal\n",
        "maxv = max(y_test_nl.max(), pred_best_b.max())  # define máximo para diagonal\n",
        "plt.plot([minv, maxv], [minv, maxv], linewidth=2)  # desenha linha de referência y=x\n",
        "plt.tight_layout()  # ajusta layout\n",
        "plt.show()  # renderiza gráfico\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resid_b = y_test_nl - pred_best_b  # calcula resíduos da PARTE B (Real - Predito)\n",
        "plt.figure(figsize=(7.5, 3.8))  # cria figura do histograma de resíduos\n",
        "plt.hist(resid_b, bins=18, alpha=0.8)  # plota distribuição dos resíduos\n",
        "plt.title(f'PARTE B - Resíduos no TESTE | {best_model_b} (Real - Predito)')  # define título\n",
        "plt.xlabel('Resíduo')  # define eixo X\n",
        "plt.ylabel('Frequência')  # define eixo Y\n",
        "plt.tight_layout()  # ajusta layout\n",
        "plt.show()  # renderiza gráfico\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.6 Visão executiva: ranking muda quando o dado muda\n",
        "\n",
        "O objetivo aqui é comparar os **mesmos modelos** nos dois cenários:\n",
        "- PARTE A (dataset linear)\n",
        "- PARTE B (dataset não-linear)\n",
        "\n",
        "Mensagem-chave: **não existe campeão universal**. O desempenho depende do padrão do dado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "comp_a = results_a[['modelo', 'rmse']].copy()  # seleciona colunas de modelo e RMSE da PARTE A\n",
        "comp_b = results_b[['modelo', 'rmse']].copy()  # seleciona colunas de modelo e RMSE da PARTE B\n",
        "comp = comp_a.merge(comp_b, on='modelo', suffixes=('_A_linear', '_B_nlinear'))  # junta resultados A e B por modelo\n",
        "comp = comp.sort_values('rmse_B_nlinear').reset_index(drop=True)  # ordena pelo desempenho na PARTE B\n",
        "\n",
        "x = np.arange(len(comp))  # cria posições no eixo X para cada modelo\n",
        "w = 0.38  # define largura das barras\n",
        "\n",
        "plt.figure(figsize=(11, 4.2))  # cria figura comparativa de RMSE\n",
        "plt.bar(x - w/2, comp['rmse_A_linear'], width=w, label='RMSE PARTE A (linear)')  # barras RMSE da PARTE A\n",
        "plt.bar(x + w/2, comp['rmse_B_nlinear'], width=w, label='RMSE PARTE B (não-linear)')  # barras RMSE da PARTE B\n",
        "plt.xticks(x, comp['modelo'], rotation=35, ha='right')  # define rótulos do eixo X com rotação\n",
        "plt.title('Comparativo executivo de RMSE no TESTE: PARTE A vs PARTE B')  # define título do gráfico\n",
        "plt.ylabel('RMSE')  # define eixo Y\n",
        "plt.legend()  # exibe legenda\n",
        "plt.tight_layout()  # ajusta layout\n",
        "plt.show()  # renderiza gráfico\n",
        "\n",
        "print('Leitura executiva: o ranking muda quando o padrão do dado muda; escolha de modelo deve ser contextual.')  # conclusão executiva\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.7 Cartões de conclusão: vencedor por parte\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_a = results_a.sort_values('rmse').iloc[0]  # captura melhor modelo da PARTE A\n",
        "best_b = results_b.sort_values('rmse').iloc[0]  # captura melhor modelo da PARTE B\n",
        "\n",
        "reason_map_a = {\n",
        "    'LinearRegression': 'venceu por simplicidade e boa aderência em padrão mais linear.',\n",
        "    'Ridge': 'venceu por estabilizar coeficientes e reduzir sensibilidade.',\n",
        "    'ElasticNet': 'venceu por equilibrar regularização L1/L2.',\n",
        "    'DecisionTree': 'venceu por capturar regras e não-linearidades locais.',\n",
        "    'RandomForest': 'venceu por robustez em relações não-lineares.',\n",
        "    'GradientBoosting': 'venceu por capturar padrões complexos com menor erro no teste.',\n",
        "    'Baseline_Naive': 'venceu porque os modelos não superaram uma referência simples.'\n",
        "}  # mapa de justificativas para a PARTE A\n",
        "\n",
        "reason_map_b = {\n",
        "    'LinearRegression': 'venceu mesmo em base não-linear, indicando relação ainda parcialmente estável.',\n",
        "    'Ridge': 'venceu por bom equilíbrio entre viés e variância.',\n",
        "    'ElasticNet': 'venceu por regularização eficiente no cenário não-linear.',\n",
        "    'DecisionTree': 'venceu por capturar limiares e regras de regime.',\n",
        "    'RandomForest': 'venceu por capturar interações e reduzir variância.',\n",
        "    'GradientBoosting': 'venceu por modelar não-linearidades de forma incremental.',\n",
        "    'Baseline_Naive': 'venceu porque os modelos não superaram a referência simples.'\n",
        "}  # mapa de justificativas para a PARTE B\n",
        "\n",
        "print('PARTE A - Vencedor no TESTE')  # título do cartão da PARTE A\n",
        "print(f\"Modelo: {best_a['modelo']} | RMSE: {best_a['rmse']:.3f} | MAE: {best_a['mae']:.3f}\")  # métricas do vencedor A\n",
        "print('Por que venceu:', reason_map_a.get(best_a['modelo'], 'desempenho superior no período de teste.'))  # justificativa A\n",
        "print('-' * 90)  # separador visual\n",
        "print('PARTE B - Vencedor no TESTE')  # título do cartão da PARTE B\n",
        "print(f\"Modelo: {best_b['modelo']} | RMSE: {best_b['rmse']:.3f} | MAE: {best_b['mae']:.3f}\")  # métricas do vencedor B\n",
        "print('Por que venceu:', reason_map_b.get(best_b['modelo'], 'desempenho superior no período de teste.'))  # justificativa B\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.8 Top 3 por parte + recomendação prática\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top3_a = results_a.sort_values('rmse').head(3).copy()  # seleciona top 3 modelos da PARTE A por RMSE\n",
        "top3_b = results_b.sort_values('rmse').head(3).copy()  # seleciona top 3 modelos da PARTE B por RMSE\n",
        "\n",
        "print('Top 3 - PARTE A (RMSE no TESTE)')  # título da lista A\n",
        "display(top3_a)  # exibe top 3 da PARTE A\n",
        "print('Top 3 - PARTE B (RMSE no TESTE)')  # título da lista B\n",
        "display(top3_b)  # exibe top 3 da PARTE B\n",
        "\n",
        "print('Recomendação prática: sempre manter baseline + 1 candidato final; validar estabilidade.')  # recomendação operacional\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.9 Como a importance muda quando o dado muda (PARTE A vs PARTE B)\n",
        "\n",
        "Aqui comparamos importâncias do mesmo tipo de modelo de árvore (RandomForest) nos dois cenários.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imp_a = pd.Series(model_rf.feature_importances_, index=features)  # extrai importâncias do RandomForest da PARTE A\n",
        "imp_b = pd.Series(model_rf_b.feature_importances_, index=features)  # extrai importâncias do RandomForest da PARTE B\n",
        "imp_comp = pd.DataFrame({'A_linear': imp_a, 'B_nlinear': imp_b})  # monta tabela comparativa A vs B\n",
        "imp_comp['media'] = imp_comp.mean(axis=1)  # calcula média das importâncias para priorizar features\n",
        "imp_top6 = imp_comp.sort_values('media', ascending=False).head(6).drop(columns='media')  # seleciona top 6 features\n",
        "imp_top6 = imp_top6.sort_values('B_nlinear', ascending=True)  # ordena para visualização mais limpa\n",
        "\n",
        "x = np.arange(len(imp_top6))  # cria posições no eixo X\n",
        "w = 0.38  # define largura das barras\n",
        "\n",
        "plt.figure(figsize=(9.5, 4.2))  # cria figura comparativa de importâncias\n",
        "plt.barh(x - w/2, imp_top6['A_linear'], height=w, label='PARTE A (linear)')  # barras da PARTE A\n",
        "plt.barh(x + w/2, imp_top6['B_nlinear'], height=w, label='PARTE B (não-linear)')  # barras da PARTE B\n",
        "plt.yticks(x, imp_top6.index)  # define labels do eixo Y com nomes das features\n",
        "plt.title('Top 6 features: mudança de importância (A vs B)')  # define título do gráfico\n",
        "plt.xlabel('Importância relativa')  # define eixo X\n",
        "plt.legend()  # exibe legenda\n",
        "plt.tight_layout()  # ajusta layout\n",
        "plt.show()  # renderiza gráfico\n",
        "\n",
        "print('Leitura FP&A: importance é sensível a regimes; correlação entre drivers pode mudar o ranking.')  # interpretação de negócio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.10 Checklist FP&A (1 minuto)\n",
        "\n",
        "- baseline obrigatório\n",
        "- split temporal\n",
        "- métricas no teste (MAE/RMSE)\n",
        "- checar overfitting (treino vs teste)\n",
        "- interpretabilidade (importance/regras) com cuidado\n",
        "- monitoramento + re-treino em mudança de regime\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Ponte final para PARTE C: quando escolher t→Y\n",
        "\n",
        "Quando séries temporais são mais adequadas:\n",
        "- quando o histórico de `y` já mostra padrão forte de tendência/sazonalidade;\n",
        "- quando os drivers explicativos são limitados ou instáveis.\n",
        "\n",
        "Na PARTE C vamos comparar:\n",
        "- ETS como referência temporal;\n",
        "- ARIMAX com Selic como exógena;\n",
        "- Prophet com eventos/regressores (opcional).\n",
        "\n",
        "Regra de ouro continua a mesma: validar no tempo (treino no passado, teste no futuro).\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) PARTE C - Séries temporais (t -> y)\n",
        "\n",
        "### O que vamos fazer\n",
        "Comparar baseline, ETS, ARIMA, ARIMAX e Prophet (opcional).\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Muitas previsões corporativas são feitas a partir do histórico da própria série.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "url_ts = 'https://raw.githubusercontent.com/ian-iania/IBMEC-BV-Modelos-Preditivos/main/data/bv_fpa_timeseries.csv'  # URL da base temporal\n",
        "df_ts = pd.read_csv(url_ts)  # leitura da base temporal\n",
        "df_ts['ds'] = pd.to_datetime(df_ts['ds'])  # conversão da data para datetime\n",
        "df_ts.head()  # exibe primeiras linhas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 4))  # cria figura da série temporal\n",
        "plt.plot(df_ts['ds'], df_ts['y'], linewidth=2)  # plota y ao longo do tempo\n",
        "plt.title('PARTE C - Série temporal y')  # define título\n",
        "plt.xlabel('Data')  # define eixo X\n",
        "plt.ylabel('y (R$ milhões)')  # define eixo Y\n",
        "plt.grid(alpha=0.3)  # adiciona grade\n",
        "plt.show()  # renderiza gráfico\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "holdout = 12  # define últimos 12 meses como teste\n",
        "train_ts = df_ts.iloc[:-holdout].copy()  # separa treino temporal\n",
        "test_ts = df_ts.iloc[-holdout:].copy()  # separa teste temporal\n",
        "y_train_ts = train_ts['y'].values  # vetor y de treino\n",
        "y_test_ts = test_ts['y'].values  # vetor y de teste\n",
        "print('Treino:', train_ts.shape, 'Teste:', test_ts.shape)  # imprime tamanhos\n",
        "print('Período treino:', train_ts['ds'].min().date(), '->', train_ts['ds'].max().date())  # imprime período de treino\n",
        "print('Período teste :', test_ts['ds'].min().date(), '->', test_ts['ds'].max().date())  # imprime período de teste\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_naive_ts = np.repeat(y_train_ts[-1], len(y_test_ts))  # cria previsão naive do período de teste\n",
        "mae_naive_ts = mean_absolute_error(y_test_ts, pred_naive_ts)  # calcula MAE baseline temporal\n",
        "rmse_naive_ts = np.sqrt(mean_squared_error(y_test_ts, pred_naive_ts))  # calcula RMSE baseline temporal\n",
        "print('Baseline MAE :', round(mae_naive_ts, 3))  # imprime MAE baseline temporal\n",
        "print('Baseline RMSE:', round(rmse_naive_ts, 3))  # imprime RMSE baseline temporal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ets = ExponentialSmoothing(train_ts['y'], trend='add', seasonal='add', seasonal_periods=12).fit(optimized=True)  # ajusta ETS\n",
        "pred_ets = ets.forecast(len(test_ts)).values  # prevê com ETS para período de teste\n",
        "mae_ets = mean_absolute_error(y_test_ts, pred_ets)  # calcula MAE ETS\n",
        "rmse_ets = np.sqrt(mean_squared_error(y_test_ts, pred_ets))  # calcula RMSE ETS\n",
        "print('ETS MAE :', round(mae_ets, 3))  # imprime MAE ETS\n",
        "print('ETS RMSE:', round(rmse_ets, 3))  # imprime RMSE ETS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arima = SARIMAX(train_ts['y'], order=(1, 1, 1), enforce_stationarity=False, enforce_invertibility=False).fit(disp=False)  # ajusta ARIMA\n",
        "pred_arima = arima.forecast(steps=len(test_ts)).values  # prevê com ARIMA no período de teste\n",
        "mae_arima = mean_absolute_error(y_test_ts, pred_arima)  # calcula MAE ARIMA\n",
        "rmse_arima = np.sqrt(mean_squared_error(y_test_ts, pred_arima))  # calcula RMSE ARIMA\n",
        "print('ARIMA MAE :', round(mae_arima, 3))  # imprime MAE ARIMA\n",
        "print('ARIMA RMSE:', round(rmse_arima, 3))  # imprime RMSE ARIMA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arimax = SARIMAX(train_ts['y'], exog=train_ts[['selic']], order=(1, 1, 1), enforce_stationarity=False, enforce_invertibility=False).fit(disp=False)  # ajusta ARIMAX com selic\n",
        "pred_arimax = arimax.forecast(steps=len(test_ts), exog=test_ts[['selic']]).values  # prevê com ARIMAX usando selic no teste\n",
        "mae_arimax = mean_absolute_error(y_test_ts, pred_arimax)  # calcula MAE ARIMAX\n",
        "rmse_arimax = np.sqrt(mean_squared_error(y_test_ts, pred_arimax))  # calcula RMSE ARIMAX\n",
        "print('ARIMAX MAE :', round(mae_arimax, 3))  # imprime MAE ARIMAX\n",
        "print('ARIMAX RMSE:', round(rmse_arimax, 3))  # imprime RMSE ARIMAX\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Prophet (opcional)\n",
        "\n",
        "Se não instalar, siga a aula normalmente com ETS/ARIMA/ARIMAX.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess  # módulo para executar comando externo\n",
        "import sys  # módulo para obter executável Python atual\n",
        "prophet_ok = False  # flag de disponibilidade do Prophet\n",
        "try:  # tenta importar Prophet já instalado\n",
        "    from prophet import Prophet  # importa Prophet quando disponível\n",
        "    prophet_ok = True  # marca disponibilidade\n",
        "    print('Prophet já disponível.')  # mensagem de sucesso\n",
        "except Exception:  # cai aqui quando Prophet não está instalado\n",
        "    print('Tentando instalar Prophet...')  # informa tentativa de instalação\n",
        "    try:  # tenta instalar via pip\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'prophet', '-q'])  # executa instalação\n",
        "        from prophet import Prophet  # tenta importar novamente após instalação\n",
        "        prophet_ok = True  # marca disponibilidade após instalar\n",
        "        print('Prophet instalado com sucesso.')  # mensagem de sucesso\n",
        "    except Exception as e:  # cai aqui quando instalação falha\n",
        "        print('Prophet indisponível nesta sessão.')  # informa indisponibilidade\n",
        "        print('Erro:', e)  # mostra detalhe do erro\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_prophet = None  # inicializa vetor de previsão Prophet\n",
        "mae_prophet = None  # inicializa MAE Prophet\n",
        "rmse_prophet = None  # inicializa RMSE Prophet\n",
        "if prophet_ok:  # executa bloco somente se Prophet disponível\n",
        "    train_prophet = train_ts[['ds', 'y', 'selic', 'evento']].copy()  # monta base de treino no formato Prophet\n",
        "    test_prophet = test_ts[['ds', 'selic', 'evento']].copy()  # monta base de teste no formato Prophet\n",
        "    m = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)  # cria modelo Prophet\n",
        "    m.add_regressor('selic')  # adiciona regressor selic\n",
        "    m.add_regressor('evento')  # adiciona regressor evento\n",
        "    m.fit(train_prophet)  # treina Prophet\n",
        "    fcst = m.predict(test_prophet)  # prevê no período de teste\n",
        "    pred_prophet = fcst['yhat'].values  # extrai vetor de previsão\n",
        "    mae_prophet = mean_absolute_error(y_test_ts, pred_prophet)  # calcula MAE Prophet\n",
        "    rmse_prophet = np.sqrt(mean_squared_error(y_test_ts, pred_prophet))  # calcula RMSE Prophet\n",
        "    print('Prophet MAE :', round(mae_prophet, 3))  # imprime MAE Prophet\n",
        "    print('Prophet RMSE:', round(rmse_prophet, 3))  # imprime RMSE Prophet\n",
        "else:  # executa quando Prophet indisponível\n",
        "    print('Prophet não executado.')  # informa que etapa foi pulada\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_c = pd.DataFrame([  # cria tabela inicial da PARTE C\n",
        "    {'modelo': 'Baseline_Naive', 'mae': mae_naive_ts, 'rmse': rmse_naive_ts},  # linha baseline\n",
        "    {'modelo': 'ETS_HoltWinters', 'mae': mae_ets, 'rmse': rmse_ets},  # linha ETS\n",
        "    {'modelo': 'ARIMA', 'mae': mae_arima, 'rmse': rmse_arima},  # linha ARIMA\n",
        "    {'modelo': 'ARIMAX_selic', 'mae': mae_arimax, 'rmse': rmse_arimax},  # linha ARIMAX\n",
        "])  # fecha DataFrame inicial\n",
        "if pred_prophet is not None:  # verifica se Prophet está disponível\n",
        "    results_c = pd.concat([results_c, pd.DataFrame([{'modelo': 'Prophet', 'mae': mae_prophet, 'rmse': rmse_prophet}])], ignore_index=True)  # acrescenta linha Prophet\n",
        "results_c = results_c.sort_values('rmse').reset_index(drop=True)  # ordena por melhor RMSE\n",
        "results_c  # exibe tabela final da PARTE C\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(11, 4))  # cria figura do gráfico final da PARTE C\n",
        "plt.plot(test_ts['ds'], y_test_ts, label='Real', color='black', linewidth=2)  # plota série real\n",
        "plt.plot(test_ts['ds'], pred_naive_ts, label='Baseline_Naive', linewidth=1.8)  # plota baseline\n",
        "plt.plot(test_ts['ds'], pred_ets, label='ETS_HoltWinters', linewidth=1.8)  # plota ETS\n",
        "plt.plot(test_ts['ds'], pred_arimax, label='ARIMAX_selic', linewidth=1.8)  # plota ARIMAX\n",
        "if pred_prophet is not None:  # verifica se previsão Prophet existe\n",
        "    plt.plot(test_ts['ds'], pred_prophet, label='Prophet', linewidth=1.8)  # plota Prophet quando disponível\n",
        "plt.title('PARTE C - Real vs Previsões (teste)')  # define título\n",
        "plt.xlabel('Data')  # define eixo X\n",
        "plt.ylabel('y (R$ milhões)')  # define eixo Y\n",
        "plt.legend()  # mostra legenda\n",
        "plt.grid(alpha=0.3)  # adiciona grade\n",
        "plt.show()  # renderiza gráfico\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Conclusão didática\n",
        "\n",
        "- **X -> y (regressão):** útil quando temos drivers para explicar a originação.\n",
        "- **t -> y (série temporal):** útil quando o histórico da própria série é forte.\n",
        "- **Regra prática:** validar no tempo e sempre comparar com baseline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Checklist FP&A\n",
        "\n",
        "- Baseline: compare sempre com referência simples.\n",
        "- Split temporal: nunca embaralhar passado e futuro.\n",
        "- Métricas: acompanhe MAE e RMSE no teste.\n",
        "- Governança: documente dados, período e versão do modelo.\n",
        "- Monitoramento: revise performance e recalibre quando necessário.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}