{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Logo BV IBMEC](https://raw.githubusercontent.com/ian-iania/IBMEC-BV-Modelos-Preditivos/main/logo-bv-ibmec-notebooks.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ian-iania/IBMEC-BV-Modelos-Preditivos/blob/main/notebooks/NB01_Regression.ipynb)\n",
        "\n",
        "# NB01 - Regressão e Séries Temporais (FP&A Banco BV)\n",
        "\n",
        "**Objetivo:** aplicar regressão e séries temporais em dados sintéticos de FP&A do BV, com linguagem simples e foco em negócio.\n",
        "**Vamos comparar baseline e modelos com split temporal e métricas MAE/RMSE, em fluxo linear.**\n",
        "**A ideia é entender o processo sem exigir conhecimento prévio de programação.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Setup do notebook\n",
        "\n",
        "### O que vamos fazer\n",
        "Importar as bibliotecas da aula.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Sem essas bibliotecas não conseguimos carregar dados, treinar modelos e visualizar resultados.\n",
        "\n",
        "### O que você deve ver no output\n",
        "Sem erro na execução.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd  # biblioteca para carregar e manipular tabelas (DataFrames)\n",
        "import numpy as np  # biblioteca para operações numéricas\n",
        "import matplotlib.pyplot as plt  # biblioteca para criar gráficos\n",
        "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet  # modelos lineares\n",
        "from sklearn.tree import DecisionTreeRegressor  # modelo de árvore de decisão\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor  # modelos de ensemble baseados em árvores\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error  # métricas de avaliação MAE e RMSE\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing  # modelo ETS (Holt-Winters)\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX  # modelo ARIMA/ARIMAX\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) PARTE A - Regressão com dataset linear (X -> y)\n",
        "\n",
        "### O que vamos fazer\n",
        "Carregar dataset linear, montar treino/teste e comparar baseline + modelos.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Esse tipo de modelo ajuda a explicar e prever a originação com base nos drivers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "url_linear = 'https://raw.githubusercontent.com/ian-iania/IBMEC-BV-Modelos-Preditivos/main/data/bv_fpa_regressao_linear.csv'  # URL do dataset linear\n",
        "df_lin = pd.read_csv(url_linear)  # leitura do CSV para DataFrame\n",
        "df_lin['ds'] = pd.to_datetime(df_lin['ds'])  # conversão da data para datetime\n",
        "df_lin.head()  # exibe as primeiras linhas da base\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Significado das colunas\n",
        "\n",
        "- `ds`: data de referência mensal (início do mês)\n",
        "- `y`: originação mensal em R$ milhões (**variável alvo**)\n",
        "- `selic`: taxa SELIC\n",
        "- `desemprego`: taxa de desemprego\n",
        "- `ltv_medio`: LTV médio\n",
        "- `spread`: spread médio\n",
        "- `marketing`: índice sintético de esforço comercial\n",
        "- `mix_auto`: participação de mix auto (0 a 1)\n",
        "- `mes`: mês numérico (1 a 12)\n",
        "\n",
        "Observação: `ds` e `y` são nomes comuns em modelagem (inclusive Prophet)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Inspeção da base (saídas separadas)\n",
        "\n",
        "Agora vamos checar tamanho, colunas e tipos em células separadas para não misturar output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_lin.shape  # mostra quantidade de linhas e colunas da base\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list(df_lin.columns)  # lista os nomes de todas as colunas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_lin.dtypes  # mostra o tipo de dado de cada coluna\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Visualização inicial\n",
        "\n",
        "### O que vamos fazer\n",
        "Ver `y` ao longo do tempo e `selic` versus `y`.\n",
        "\n",
        "### O que você deve ver no output\n",
        "Um gráfico de linha e um de dispersão.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 4))  # cria a figura do gráfico temporal\n",
        "plt.plot(df_lin['ds'], df_lin['y'], linewidth=2)  # plota y ao longo do tempo\n",
        "plt.title('PARTE A - Originação (y) ao longo do tempo')  # define o título\n",
        "plt.xlabel('Data')  # define eixo X\n",
        "plt.ylabel('y (R$ milhões)')  # define eixo Y\n",
        "plt.grid(alpha=0.3)  # adiciona grade\n",
        "plt.show()  # renderiza gráfico\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))  # cria a figura do gráfico de dispersão\n",
        "plt.scatter(df_lin['selic'], df_lin['y'], alpha=0.75)  # plota selic no eixo X e y no eixo Y\n",
        "plt.title('PARTE A - SELIC vs y')  # define título\n",
        "plt.xlabel('SELIC')  # define eixo X\n",
        "plt.ylabel('y (R$ milhões)')  # define eixo Y\n",
        "plt.grid(alpha=0.3)  # adiciona grade\n",
        "plt.show()  # renderiza gráfico\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Split temporal e baseline\n",
        "\n",
        "### O que vamos fazer\n",
        "Separar treino/teste no tempo (80%/20%, sem embaralhar) e calcular baseline naive.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "No mundo real, o modelo sempre prevê períodos futuros com base no passado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = ['selic', 'desemprego', 'ltv_medio', 'spread', 'marketing', 'mix_auto', 'mes']  # lista de variáveis explicativas\n",
        "split_idx = int(len(df_lin) * 0.8)  # define ponto de corte para treino e teste\n",
        "train_lin = df_lin.iloc[:split_idx].copy()  # seleciona linhas de treino\n",
        "train_lin = train_lin.sort_values('ds')  # garante ordenação temporal no treino\n",
        "test_lin = df_lin.iloc[split_idx:].copy()  # seleciona linhas de teste\n",
        "test_lin = test_lin.sort_values('ds')  # garante ordenação temporal no teste\n",
        "X_train_lin = train_lin[features]  # cria matriz X de treino\n",
        "X_test_lin = test_lin[features]  # cria matriz X de teste\n",
        "y_train_lin = train_lin['y']  # cria vetor y de treino\n",
        "y_test_lin = test_lin['y']  # cria vetor y de teste\n",
        "print('Treino:', X_train_lin.shape, 'Teste:', X_test_lin.shape)  # imprime tamanhos de treino e teste\n",
        "print('Período treino:', train_lin['ds'].min().date(), '->', train_lin['ds'].max().date())  # imprime intervalo de treino\n",
        "print('Período teste :', test_lin['ds'].min().date(), '->', test_lin['ds'].max().date())  # imprime intervalo de teste\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_value_lin = y_train_lin.iloc[-1]  # pega o último valor de y no treino\n",
        "pred_baseline_lin = np.repeat(baseline_value_lin, len(y_test_lin))  # repete esse valor para todo o teste\n",
        "mae_baseline_lin = mean_absolute_error(y_test_lin, pred_baseline_lin)  # calcula MAE do baseline\n",
        "rmse_baseline_lin = np.sqrt(mean_squared_error(y_test_lin, pred_baseline_lin))  # calcula RMSE do baseline\n",
        "print('Baseline MAE :', round(mae_baseline_lin, 3))  # imprime MAE\n",
        "print('Baseline RMSE:', round(rmse_baseline_lin, 3))  # imprime RMSE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5 Modelos de regressão (execução linear)\n",
        "\n",
        "Vamos treinar um modelo por vez, com uma célula de texto antes de cada treino.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo 1: LinearRegression\n",
        "\n",
        "**O que é:** regressão linear clássica.\n",
        "**Por que usar:** ótimo ponto de partida e fácil de interpretar.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_lr = LinearRegression()  # cria o modelo de regressão linear\n",
        "model_lr.fit(X_train_lin, y_train_lin)  # treina o modelo\n",
        "pred_lr = model_lr.predict(X_test_lin)  # gera previsão no teste\n",
        "mae_lr = mean_absolute_error(y_test_lin, pred_lr)  # calcula MAE\n",
        "rmse_lr = np.sqrt(mean_squared_error(y_test_lin, pred_lr))  # calcula RMSE\n",
        "print('LinearRegression RMSE:', round(rmse_lr, 3))  # imprime RMSE do modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Por que esse resultado importa:** serve como referência de modelo supervisionado simples para comparar com modelos mais sofisticados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo 2: Ridge\n",
        "\n",
        "**O que é:** regressão linear com regularização L2.\n",
        "**Por que usar:** reduz sensibilidade a coeficientes extremos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_ridge = Ridge(alpha=1.0, random_state=42)  # cria modelo Ridge\n",
        "model_ridge.fit(X_train_lin, y_train_lin)  # treina o Ridge\n",
        "pred_ridge = model_ridge.predict(X_test_lin)  # gera previsão no teste\n",
        "mae_ridge = mean_absolute_error(y_test_lin, pred_ridge)  # calcula MAE\n",
        "rmse_ridge = np.sqrt(mean_squared_error(y_test_lin, pred_ridge))  # calcula RMSE\n",
        "print('Ridge RMSE:', round(rmse_ridge, 3))  # imprime RMSE do modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Por que esse resultado importa:** mostra se uma versão regularizada melhora estabilidade em relação ao linear puro.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo 3: ElasticNet\n",
        "\n",
        "**O que é:** combina penalização L1 e L2.\n",
        "**Por que usar:** pode ajudar quando há correlação entre variáveis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_en = ElasticNet(alpha=0.05, l1_ratio=0.5, random_state=42, max_iter=5000)  # cria modelo ElasticNet\n",
        "model_en.fit(X_train_lin, y_train_lin)  # treina o ElasticNet\n",
        "pred_en = model_en.predict(X_test_lin)  # gera previsão no teste\n",
        "mae_en = mean_absolute_error(y_test_lin, pred_en)  # calcula MAE\n",
        "rmse_en = np.sqrt(mean_squared_error(y_test_lin, pred_en))  # calcula RMSE\n",
        "print('ElasticNet RMSE:', round(rmse_en, 3))  # imprime RMSE do modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Por que esse resultado importa:** adiciona mais um candidato linear para comparação justa com modelos não-lineares.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo 4: DecisionTree\n",
        "\n",
        "**O que é:** árvore de decisão.\n",
        "**Por que usar:** captura relações não-lineares de forma simples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_tree = DecisionTreeRegressor(max_depth=4, random_state=42)  # cria modelo de árvore\n",
        "model_tree.fit(X_train_lin, y_train_lin)  # treina árvore\n",
        "pred_tree = model_tree.predict(X_test_lin)  # gera previsão no teste\n",
        "mae_tree = mean_absolute_error(y_test_lin, pred_tree)  # calcula MAE\n",
        "rmse_tree = np.sqrt(mean_squared_error(y_test_lin, pred_tree))  # calcula RMSE\n",
        "print('DecisionTree RMSE:', round(rmse_tree, 3))  # imprime RMSE do modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Por que esse resultado importa:** ajuda a verificar se padrões não-lineares já aparecem no dataset linear.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo 5: RandomForest\n",
        "\n",
        "**O que é:** conjunto de várias árvores (ensemble).\n",
        "**Por que usar:** reduz variância da árvore única e costuma performar bem.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_rf = RandomForestRegressor(n_estimators=300, max_depth=6, random_state=42)  # cria RandomForest\n",
        "model_rf.fit(X_train_lin, y_train_lin)  # treina RandomForest\n",
        "pred_rf = model_rf.predict(X_test_lin)  # gera previsão no teste\n",
        "mae_rf = mean_absolute_error(y_test_lin, pred_rf)  # calcula MAE\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test_lin, pred_rf))  # calcula RMSE\n",
        "print('RandomForest RMSE:', round(rmse_rf, 3))  # imprime RMSE do modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Por que esse resultado importa:** é um modelo forte para comparação em dados tabulares de negócio.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo 6: GradientBoosting\n",
        "\n",
        "**O que é:** modelo de boosting com árvores sequenciais.\n",
        "**Por que usar:** aprende correções progressivas e pode capturar padrões mais complexos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_gbm = GradientBoostingRegressor(random_state=42)  # cria modelo GradientBoosting\n",
        "model_gbm.fit(X_train_lin, y_train_lin)  # treina GradientBoosting\n",
        "pred_gbm = model_gbm.predict(X_test_lin)  # gera previsão no teste\n",
        "mae_gbm = mean_absolute_error(y_test_lin, pred_gbm)  # calcula MAE\n",
        "rmse_gbm = np.sqrt(mean_squared_error(y_test_lin, pred_gbm))  # calcula RMSE\n",
        "print('GradientBoosting RMSE:', round(rmse_gbm, 3))  # imprime RMSE do modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Por que esse resultado importa:** permite testar um modelo não-linear poderoso em comparação com os demais.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.6 Tabela final e gráfico comparativo (PARTE A)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_a = pd.DataFrame([  # cria tabela de métricas da PARTE A\n",
        "    {'modelo': 'Baseline_Naive', 'mae': mae_baseline_lin, 'rmse': rmse_baseline_lin},  # baseline\n",
        "    {'modelo': 'LinearRegression', 'mae': mae_lr, 'rmse': rmse_lr},  # linear\n",
        "    {'modelo': 'Ridge', 'mae': mae_ridge, 'rmse': rmse_ridge},  # ridge\n",
        "    {'modelo': 'ElasticNet', 'mae': mae_en, 'rmse': rmse_en},  # elasticnet\n",
        "    {'modelo': 'DecisionTree', 'mae': mae_tree, 'rmse': rmse_tree},  # árvore\n",
        "    {'modelo': 'RandomForest', 'mae': mae_rf, 'rmse': rmse_rf},  # random forest\n",
        "    {'modelo': 'GradientBoosting', 'mae': mae_gbm, 'rmse': rmse_gbm},  # gradient boosting\n",
        "]).sort_values('rmse').reset_index(drop=True)  # ordena por melhor RMSE\n",
        "results_a  # exibe ranking final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_linear_name = results_a[results_a['modelo'].isin(['LinearRegression', 'Ridge', 'ElasticNet'])].iloc[0]['modelo']  # seleciona melhor linear\n",
        "best_nonlinear_name = results_a[results_a['modelo'].isin(['DecisionTree', 'RandomForest', 'GradientBoosting'])].iloc[0]['modelo']  # seleciona melhor não-linear\n",
        "pred_map_a = {  # dicionário com previsões da PARTE A\n",
        "    'LinearRegression': pred_lr,  # previsões linear\n",
        "    'Ridge': pred_ridge,  # previsões ridge\n",
        "    'ElasticNet': pred_en,  # previsões elasticnet\n",
        "    'DecisionTree': pred_tree,  # previsões árvore\n",
        "    'RandomForest': pred_rf,  # previsões random forest\n",
        "    'GradientBoosting': pred_gbm,  # previsões gradient boosting\n",
        "}  # fim do dicionário\n",
        "plt.figure(figsize=(11, 4))  # cria figura para comparação de previsões\n",
        "plt.plot(test_lin['ds'], y_test_lin.values, label='Real', color='black', linewidth=2)  # linha real\n",
        "plt.plot(test_lin['ds'], pred_baseline_lin, label='Baseline_Naive', linewidth=1.8)  # linha baseline\n",
        "plt.plot(test_lin['ds'], pred_map_a[best_linear_name], label=f'Melhor linear: {best_linear_name}', linewidth=1.8)  # linha melhor linear\n",
        "plt.plot(test_lin['ds'], pred_map_a[best_nonlinear_name], label=f'Melhor não-linear: {best_nonlinear_name}', linewidth=1.8)  # linha melhor não-linear\n",
        "plt.title('PARTE A - Real vs Previsto (teste)')  # título do gráfico\n",
        "plt.xlabel('Data')  # eixo X\n",
        "plt.ylabel('y (R$ milhões)')  # eixo Y\n",
        "plt.legend()  # legenda\n",
        "plt.grid(alpha=0.3)  # grade\n",
        "plt.show()  # renderiza gráfico\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.7 Feature importance (introdução)\n",
        "\n",
        "### O que vamos fazer\n",
        "Medir importância das variáveis para RandomForest e GradientBoosting.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Ajuda a priorizar quais drivers merecem atenção na discussão gerencial.\n",
        "\n",
        "### Como interpretar\n",
        "Importância alta sugere influência preditiva, mas **não prova causalidade**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_imp = pd.Series(model_rf.feature_importances_, index=features).sort_values(ascending=True)  # calcula importâncias do RandomForest\n",
        "gbm_imp = pd.Series(model_gbm.feature_importances_, index=features).sort_values(ascending=True)  # calcula importâncias do GradientBoosting\n",
        "rf_imp  # exibe vetor de importâncias do RandomForest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))  # cria figura do RandomForest\n",
        "plt.barh(rf_imp.index, rf_imp.values)  # plota barras horizontais do RandomForest\n",
        "plt.title('Importância - RandomForest')  # define título do gráfico\n",
        "plt.grid(axis='x', alpha=0.3)  # adiciona grade horizontal\n",
        "plt.show()  # renderiza gráfico\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))  # cria figura do GradientBoosting\n",
        "plt.barh(gbm_imp.index, gbm_imp.values)  # plota barras horizontais do GradientBoosting\n",
        "plt.title('Importância - GradientBoosting')  # define título do gráfico\n",
        "plt.grid(axis='x', alpha=0.3)  # adiciona grade horizontal\n",
        "plt.show()  # renderiza gráfico\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) PARTE B - Mesmo pipeline no dataset não-linear\n",
        "\n",
        "### O que vamos fazer\n",
        "Repetir o fluxo no dataset não-linear.\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Em cenários com limiares/interações, modelos não-lineares tendem a capturar melhor os padrões.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Carregar e preparar base não-linear\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "url_nlin = 'https://raw.githubusercontent.com/ian-iania/IBMEC-BV-Modelos-Preditivos/main/data/bv_fpa_regressao_nonlinear.csv'  # URL da base não-linear\n",
        "df_nlin = pd.read_csv(url_nlin)  # leitura da base não-linear\n",
        "df_nlin['ds'] = pd.to_datetime(df_nlin['ds'])  # conversão da data para datetime\n",
        "df_nlin.head()  # exibe primeiras linhas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_idx_b = int(len(df_nlin) * 0.8)  # define ponto de corte de treino/teste\n",
        "train_nlin = df_nlin.iloc[:split_idx_b].copy()  # recorte de treino da base não-linear\n",
        "train_nlin = train_nlin.sort_values('ds')  # garante ordenação temporal de treino\n",
        "test_nlin = df_nlin.iloc[split_idx_b:].copy()  # recorte de teste da base não-linear\n",
        "test_nlin = test_nlin.sort_values('ds')  # garante ordenação temporal de teste\n",
        "X_train_nlin = train_nlin[features]  # monta X de treino\n",
        "X_test_nlin = test_nlin[features]  # monta X de teste\n",
        "y_train_nlin = train_nlin['y']  # monta y de treino\n",
        "y_test_nlin = test_nlin['y']  # monta y de teste\n",
        "baseline_value_nlin = y_train_nlin.iloc[-1]  # captura último valor de treino para baseline\n",
        "pred_baseline_nlin = np.repeat(baseline_value_nlin, len(y_test_nlin))  # gera previsão baseline\n",
        "mae_baseline_nlin = mean_absolute_error(y_test_nlin, pred_baseline_nlin)  # calcula MAE do baseline\n",
        "rmse_baseline_nlin = np.sqrt(mean_squared_error(y_test_nlin, pred_baseline_nlin))  # calcula RMSE do baseline\n",
        "print('Baseline RMSE (não-linear):', round(rmse_baseline_nlin, 3))  # imprime RMSE baseline da PARTE B\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Treinar modelos na base não-linear\n",
        "\n",
        "Vamos repetir exatamente os mesmos modelos da PARTE A para comparar de forma justa.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo LinearRegression (PARTE B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_lr_b = LinearRegression()  # cria LinearRegression da PARTE B\n",
        "model_lr_b.fit(X_train_nlin, y_train_nlin)  # treina LinearRegression na base não-linear\n",
        "pred_lr_b = model_lr_b.predict(X_test_nlin)  # gera previsão da LinearRegression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo Ridge (PARTE B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_ridge_b = Ridge(alpha=1.0, random_state=42)  # cria Ridge da PARTE B\n",
        "model_ridge_b.fit(X_train_nlin, y_train_nlin)  # treina Ridge na base não-linear\n",
        "pred_ridge_b = model_ridge_b.predict(X_test_nlin)  # gera previsão do Ridge\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo ElasticNet (PARTE B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_en_b = ElasticNet(alpha=0.05, l1_ratio=0.5, random_state=42, max_iter=5000)  # cria ElasticNet da PARTE B\n",
        "model_en_b.fit(X_train_nlin, y_train_nlin)  # treina ElasticNet na base não-linear\n",
        "pred_en_b = model_en_b.predict(X_test_nlin)  # gera previsão do ElasticNet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo DecisionTree (PARTE B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_tree_b = DecisionTreeRegressor(max_depth=4, random_state=42)  # cria árvore da PARTE B\n",
        "model_tree_b.fit(X_train_nlin, y_train_nlin)  # treina árvore na base não-linear\n",
        "pred_tree_b = model_tree_b.predict(X_test_nlin)  # gera previsão da árvore\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo RandomForest (PARTE B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_rf_b = RandomForestRegressor(n_estimators=300, max_depth=6, random_state=42)  # cria RandomForest da PARTE B\n",
        "model_rf_b.fit(X_train_nlin, y_train_nlin)  # treina RandomForest na base não-linear\n",
        "pred_rf_b = model_rf_b.predict(X_test_nlin)  # gera previsão do RandomForest\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modelo GradientBoosting (PARTE B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_gbm_b = GradientBoostingRegressor(random_state=42)  # cria GradientBoosting da PARTE B\n",
        "model_gbm_b.fit(X_train_nlin, y_train_nlin)  # treina GradientBoosting na base não-linear\n",
        "pred_gbm_b = model_gbm_b.predict(X_test_nlin)  # gera previsão do GradientBoosting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Tabela de resultados da PARTE B\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Garantia para evitar NameError se alguma célula de treino tiver sido pulada\n",
        "if 'pred_lr_b' not in globals():  # verifica se previsões da PARTE B existem\n",
        "    model_lr_b = LinearRegression()  # recria LinearRegression da PARTE B\n",
        "    model_lr_b.fit(X_train_nlin, y_train_nlin)  # retreina LinearRegression da PARTE B\n",
        "    pred_lr_b = model_lr_b.predict(X_test_nlin)  # regenera previsão da LinearRegression da PARTE B\n",
        "if 'pred_ridge_b' not in globals():  # verifica previsão do Ridge na PARTE B\n",
        "    model_ridge_b = Ridge(alpha=1.0, random_state=42)  # recria Ridge da PARTE B\n",
        "    model_ridge_b.fit(X_train_nlin, y_train_nlin)  # retreina Ridge da PARTE B\n",
        "    pred_ridge_b = model_ridge_b.predict(X_test_nlin)  # regenera previsão do Ridge da PARTE B\n",
        "if 'pred_en_b' not in globals():  # verifica previsão do ElasticNet na PARTE B\n",
        "    model_en_b = ElasticNet(alpha=0.05, l1_ratio=0.5, random_state=42, max_iter=5000)  # recria ElasticNet da PARTE B\n",
        "    model_en_b.fit(X_train_nlin, y_train_nlin)  # retreina ElasticNet da PARTE B\n",
        "    pred_en_b = model_en_b.predict(X_test_nlin)  # regenera previsão do ElasticNet da PARTE B\n",
        "if 'pred_tree_b' not in globals():  # verifica previsão da árvore na PARTE B\n",
        "    model_tree_b = DecisionTreeRegressor(max_depth=4, random_state=42)  # recria árvore da PARTE B\n",
        "    model_tree_b.fit(X_train_nlin, y_train_nlin)  # retreina árvore da PARTE B\n",
        "    pred_tree_b = model_tree_b.predict(X_test_nlin)  # regenera previsão da árvore da PARTE B\n",
        "if 'pred_rf_b' not in globals():  # verifica previsão do RandomForest na PARTE B\n",
        "    model_rf_b = RandomForestRegressor(n_estimators=300, max_depth=6, random_state=42)  # recria RandomForest da PARTE B\n",
        "    model_rf_b.fit(X_train_nlin, y_train_nlin)  # retreina RandomForest da PARTE B\n",
        "    pred_rf_b = model_rf_b.predict(X_test_nlin)  # regenera previsão do RandomForest da PARTE B\n",
        "if 'pred_gbm_b' not in globals():  # verifica previsão do GradientBoosting na PARTE B\n",
        "    model_gbm_b = GradientBoostingRegressor(random_state=42)  # recria GradientBoosting da PARTE B\n",
        "    model_gbm_b.fit(X_train_nlin, y_train_nlin)  # retreina GradientBoosting da PARTE B\n",
        "    pred_gbm_b = model_gbm_b.predict(X_test_nlin)  # regenera previsão do GradientBoosting da PARTE B\n",
        "\n",
        "results_b = pd.DataFrame([  # cria tabela de resultados da PARTE B\n",
        "    {'modelo': 'Baseline_Naive', 'mae': mae_baseline_nlin, 'rmse': rmse_baseline_nlin},  # linha baseline\n",
        "    {'modelo': 'LinearRegression', 'mae': mean_absolute_error(y_test_nlin, pred_lr_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_lr_b))},  # linha linear\n",
        "    {'modelo': 'Ridge', 'mae': mean_absolute_error(y_test_nlin, pred_ridge_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_ridge_b))},  # linha ridge\n",
        "    {'modelo': 'ElasticNet', 'mae': mean_absolute_error(y_test_nlin, pred_en_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_en_b))},  # linha elasticnet\n",
        "    {'modelo': 'DecisionTree', 'mae': mean_absolute_error(y_test_nlin, pred_tree_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_tree_b))},  # linha árvore\n",
        "    {'modelo': 'RandomForest', 'mae': mean_absolute_error(y_test_nlin, pred_rf_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_rf_b))},  # linha random forest\n",
        "    {'modelo': 'GradientBoosting', 'mae': mean_absolute_error(y_test_nlin, pred_gbm_b), 'rmse': np.sqrt(mean_squared_error(y_test_nlin, pred_gbm_b))},  # linha gradient boosting\n",
        "]).sort_values('rmse').reset_index(drop=True)  # ordena por melhor RMSE\n",
        "results_b  # exibe ranking final da PARTE B\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_linear_b = results_b[results_b['modelo'].isin(['LinearRegression', 'Ridge', 'ElasticNet'])].iloc[0]['modelo']  # identifica melhor linear da PARTE B\n",
        "best_nonlinear_b = results_b[results_b['modelo'].isin(['DecisionTree', 'RandomForest', 'GradientBoosting'])].iloc[0]['modelo']  # identifica melhor não-linear da PARTE B\n",
        "pred_map_b = {  # cria dicionário de previsões da PARTE B\n",
        "    'LinearRegression': pred_lr_b,  # previsão LinearRegression\n",
        "    'Ridge': pred_ridge_b,  # previsão Ridge\n",
        "    'ElasticNet': pred_en_b,  # previsão ElasticNet\n",
        "    'DecisionTree': pred_tree_b,  # previsão DecisionTree\n",
        "    'RandomForest': pred_rf_b,  # previsão RandomForest\n",
        "    'GradientBoosting': pred_gbm_b,  # previsão GradientBoosting\n",
        "}  # fim do dicionário\n",
        "plt.figure(figsize=(11, 4))  # cria figura comparativa da PARTE B\n",
        "plt.plot(test_nlin['ds'], y_test_nlin.values, label='Real', color='black', linewidth=2)  # plota série real\n",
        "plt.plot(test_nlin['ds'], pred_map_b[best_linear_b], label=f'Melhor linear: {best_linear_b}', linewidth=1.8)  # plota melhor linear\n",
        "plt.plot(test_nlin['ds'], pred_map_b[best_nonlinear_b], label=f'Melhor não-linear: {best_nonlinear_b}', linewidth=1.8)  # plota melhor não-linear\n",
        "plt.title('PARTE B - Melhor linear vs melhor não-linear (teste)')  # define título\n",
        "plt.xlabel('Data')  # define eixo X\n",
        "plt.ylabel('y (R$ milhões)')  # define eixo Y\n",
        "plt.legend()  # exibe legenda\n",
        "plt.grid(alpha=0.3)  # adiciona grade\n",
        "plt.show()  # renderiza gráfico\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) PARTE C - Séries temporais (t -> y)\n",
        "\n",
        "### O que vamos fazer\n",
        "Comparar baseline, ETS, ARIMA, ARIMAX e Prophet (opcional).\n",
        "\n",
        "### Por que isso importa para FP&A\n",
        "Muitas previsões corporativas são feitas a partir do histórico da própria série.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "url_ts = 'https://raw.githubusercontent.com/ian-iania/IBMEC-BV-Modelos-Preditivos/main/data/bv_fpa_timeseries.csv'  # URL da base temporal\n",
        "df_ts = pd.read_csv(url_ts)  # leitura da base temporal\n",
        "df_ts['ds'] = pd.to_datetime(df_ts['ds'])  # conversão da data para datetime\n",
        "df_ts.head()  # exibe primeiras linhas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 4))  # cria figura da série temporal\n",
        "plt.plot(df_ts['ds'], df_ts['y'], linewidth=2)  # plota y ao longo do tempo\n",
        "plt.title('PARTE C - Série temporal y')  # define título\n",
        "plt.xlabel('Data')  # define eixo X\n",
        "plt.ylabel('y (R$ milhões)')  # define eixo Y\n",
        "plt.grid(alpha=0.3)  # adiciona grade\n",
        "plt.show()  # renderiza gráfico\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "holdout = 12  # define últimos 12 meses como teste\n",
        "train_ts = df_ts.iloc[:-holdout].copy()  # separa treino temporal\n",
        "test_ts = df_ts.iloc[-holdout:].copy()  # separa teste temporal\n",
        "y_train_ts = train_ts['y'].values  # vetor y de treino\n",
        "y_test_ts = test_ts['y'].values  # vetor y de teste\n",
        "print('Treino:', train_ts.shape, 'Teste:', test_ts.shape)  # imprime tamanhos\n",
        "print('Período treino:', train_ts['ds'].min().date(), '->', train_ts['ds'].max().date())  # imprime período de treino\n",
        "print('Período teste :', test_ts['ds'].min().date(), '->', test_ts['ds'].max().date())  # imprime período de teste\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_naive_ts = np.repeat(y_train_ts[-1], len(y_test_ts))  # cria previsão naive do período de teste\n",
        "mae_naive_ts = mean_absolute_error(y_test_ts, pred_naive_ts)  # calcula MAE baseline temporal\n",
        "rmse_naive_ts = np.sqrt(mean_squared_error(y_test_ts, pred_naive_ts))  # calcula RMSE baseline temporal\n",
        "print('Baseline MAE :', round(mae_naive_ts, 3))  # imprime MAE baseline temporal\n",
        "print('Baseline RMSE:', round(rmse_naive_ts, 3))  # imprime RMSE baseline temporal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ets = ExponentialSmoothing(train_ts['y'], trend='add', seasonal='add', seasonal_periods=12).fit(optimized=True)  # ajusta ETS\n",
        "aets = ets  # alias simples para leitura didática\n",
        "pred_ets = aets.forecast(len(test_ts)).values  # prevê com ETS para período de teste\n",
        "mae_ets = mean_absolute_error(y_test_ts, pred_ets)  # calcula MAE ETS\n",
        "rmse_ets = np.sqrt(mean_squared_error(y_test_ts, pred_ets))  # calcula RMSE ETS\n",
        "print('ETS MAE :', round(mae_ets, 3))  # imprime MAE ETS\n",
        "print('ETS RMSE:', round(rmse_ets, 3))  # imprime RMSE ETS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arima = SARIMAX(train_ts['y'], order=(1, 1, 1), enforce_stationarity=False, enforce_invertibility=False).fit(disp=False)  # ajusta ARIMA\n",
        "pred_arima = arima.forecast(steps=len(test_ts)).values  # prevê com ARIMA no período de teste\n",
        "mae_arima = mean_absolute_error(y_test_ts, pred_arima)  # calcula MAE ARIMA\n",
        "rmse_arima = np.sqrt(mean_squared_error(y_test_ts, pred_arima))  # calcula RMSE ARIMA\n",
        "print('ARIMA MAE :', round(mae_arima, 3))  # imprime MAE ARIMA\n",
        "print('ARIMA RMSE:', round(rmse_arima, 3))  # imprime RMSE ARIMA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arimax = SARIMAX(train_ts['y'], exog=train_ts[['selic']], order=(1, 1, 1), enforce_stationarity=False, enforce_invertibility=False).fit(disp=False)  # ajusta ARIMAX com selic\n",
        "pred_arimax = arimax.forecast(steps=len(test_ts), exog=test_ts[['selic']]).values  # prevê com ARIMAX usando selic no teste\n",
        "mae_arimax = mean_absolute_error(y_test_ts, pred_arimax)  # calcula MAE ARIMAX\n",
        "rmse_arimax = np.sqrt(mean_squared_error(y_test_ts, pred_arimax))  # calcula RMSE ARIMAX\n",
        "print('ARIMAX MAE :', round(mae_arimax, 3))  # imprime MAE ARIMAX\n",
        "print('ARIMAX RMSE:', round(rmse_arimax, 3))  # imprime RMSE ARIMAX\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Prophet (opcional)\n",
        "\n",
        "Se não instalar, siga a aula normalmente com ETS/ARIMA/ARIMAX.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess  # módulo para executar comando externo\n",
        "import sys  # módulo para obter executável Python atual\n",
        "prophet_ok = False  # flag de disponibilidade do Prophet\n",
        "try:  # tenta importar Prophet já instalado\n",
        "    from prophet import Prophet  # importa Prophet quando disponível\n",
        "    prophet_ok = True  # marca disponibilidade\n",
        "    print('Prophet já disponível.')  # mensagem de sucesso\n",
        "except Exception:  # cai aqui quando Prophet não está instalado\n",
        "    print('Tentando instalar Prophet...')  # informa tentativa de instalação\n",
        "    try:  # tenta instalar via pip\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'prophet', '-q'])  # executa instalação\n",
        "        from prophet import Prophet  # tenta importar novamente após instalação\n",
        "        prophet_ok = True  # marca disponibilidade após instalar\n",
        "        print('Prophet instalado com sucesso.')  # mensagem de sucesso\n",
        "    except Exception as e:  # cai aqui quando instalação falha\n",
        "        print('Prophet indisponível nesta sessão.')  # informa indisponibilidade\n",
        "        print('Erro:', e)  # mostra detalhe do erro\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_prophet = None  # inicializa vetor de previsão Prophet\n",
        "mae_prophet = None  # inicializa MAE Prophet\n",
        "rmse_prophet = None  # inicializa RMSE Prophet\n",
        "if prophet_ok:  # executa bloco somente se Prophet disponível\n",
        "    train_prophet = train_ts[['ds', 'y', 'selic', 'evento']].copy()  # monta base de treino no formato Prophet\n",
        "    test_prophet = test_ts[['ds', 'selic', 'evento']].copy()  # monta base de teste no formato Prophet\n",
        "    m = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)  # cria modelo Prophet\n",
        "    m.add_regressor('selic')  # adiciona regressor selic\n",
        "    m.add_regressor('evento')  # adiciona regressor evento\n",
        "    m.fit(train_prophet)  # treina Prophet\n",
        "    fcst = m.predict(test_prophet)  # prevê no período de teste\n",
        "    pred_prophet = fcst['yhat'].values  # extrai vetor de previsão\n",
        "    mae_prophet = mean_absolute_error(y_test_ts, pred_prophet)  # calcula MAE Prophet\n",
        "    rmse_prophet = np.sqrt(mean_squared_error(y_test_ts, pred_prophet))  # calcula RMSE Prophet\n",
        "    print('Prophet MAE :', round(mae_prophet, 3))  # imprime MAE Prophet\n",
        "    print('Prophet RMSE:', round(rmse_prophet, 3))  # imprime RMSE Prophet\n",
        "else:  # executa quando Prophet indisponível\n",
        "    print('Prophet não executado.')  # informa que etapa foi pulada\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_c = pd.DataFrame([  # cria tabela inicial da PARTE C\n",
        "    {'modelo': 'Baseline_Naive', 'mae': mae_naive_ts, 'rmse': rmse_naive_ts},  # linha baseline\n",
        "    {'modelo': 'ETS_HoltWinters', 'mae': mae_ets, 'rmse': rmse_ets},  # linha ETS\n",
        "    {'modelo': 'ARIMA', 'mae': mae_arima, 'rmse': rmse_arima},  # linha ARIMA\n",
        "    {'modelo': 'ARIMAX_selic', 'mae': mae_arimax, 'rmse': rmse_arimax},  # linha ARIMAX\n",
        "])  # fecha DataFrame inicial\n",
        "if pred_prophet is not None:  # verifica se Prophet está disponível\n",
        "    results_c = pd.concat([results_c, pd.DataFrame([{'modelo': 'Prophet', 'mae': mae_prophet, 'rmse': rmse_prophet}])], ignore_index=True)  # acrescenta linha Prophet\n",
        "results_c = results_c.sort_values('rmse').reset_index(drop=True)  # ordena por melhor RMSE\n",
        "results_c  # exibe tabela final da PARTE C\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(11, 4))  # cria figura do gráfico final da PARTE C\n",
        "plt.plot(test_ts['ds'], y_test_ts, label='Real', color='black', linewidth=2)  # plota série real\n",
        "plt.plot(test_ts['ds'], pred_naive_ts, label='Baseline_Naive', linewidth=1.8)  # plota baseline\n",
        "plt.plot(test_ts['ds'], pred_ets, label='ETS_HoltWinters', linewidth=1.8)  # plota ETS\n",
        "plt.plot(test_ts['ds'], pred_arimax, label='ARIMAX_selic', linewidth=1.8)  # plota ARIMAX\n",
        "if pred_prophet is not None:  # verifica se previsão Prophet existe\n",
        "    plt.plot(test_ts['ds'], pred_prophet, label='Prophet', linewidth=1.8)  # plota Prophet quando disponível\n",
        "plt.title('PARTE C - Real vs Previsões (teste)')  # define título\n",
        "plt.xlabel('Data')  # define eixo X\n",
        "plt.ylabel('y (R$ milhões)')  # define eixo Y\n",
        "plt.legend()  # mostra legenda\n",
        "plt.grid(alpha=0.3)  # adiciona grade\n",
        "plt.show()  # renderiza gráfico\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Conclusão didática\n",
        "\n",
        "- **X -> y (regressão):** útil quando temos drivers para explicar a originação.\n",
        "- **t -> y (série temporal):** útil quando o histórico da própria série é forte.\n",
        "- **Regra prática:** validar no tempo e sempre comparar com baseline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Checklist FP&A\n",
        "\n",
        "- Baseline: compare sempre com referência simples.\n",
        "- Split temporal: nunca embaralhar passado e futuro.\n",
        "- Métricas: acompanhe MAE e RMSE no teste.\n",
        "- Governança: documente dados, período e versão do modelo.\n",
        "- Monitoramento: revise performance e recalibre quando necessário.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}